# ğŸŒ Proyecto Terremotos â€” IngenierÃ­a de caracterÃ­sticas y anÃ¡lisis anual

Este proyecto realiza **limpieza**, **ingenierÃ­a de caracterÃ­sticas** y **anÃ¡lisis anual** sobre un dataset sÃ­smico, generando un CSV normalizado y visualizaciones para entender la **magnitud mÃ¡xima por aÃ±o**, la **magnitud inmediatamente anterior** a ese evento y el **recuento de sismos**.

Incluye:
- Un **notebook** (`proyecto_terremoto.ipynb`) para exploraciÃ³n y visualizaciÃ³n.
- Un **script** (`guardar.py`) para ejecutar la transformaciÃ³n y guardar resultados de forma reproducible.

> Nota: el pipeline contempla columnas tÃ­picas de momento sÃ­smico como `Mrr`, `Mtt`, `Mpp`, `Mrt` y de tiempo (`year`, `month`, `day`, `hour`, `minute`, `second`). Ajusta los nombres si tu dataset difiere.


---

## ğŸ§° TecnologÃ­as

| CategorÃ­a              | Herramienta / LibrerÃ­a |
|-----------------------:|------------------------|
| Lenguaje               | Python 3.9+ |
| Datos                  | pandas, numpy |
| VisualizaciÃ³n          | matplotlib, seaborn |
| Tablas en consola      | tabulate |
| Entorno recomendado    | Jupyter Notebook / VS Code + venv |


---

## ğŸ“‚ Estructura

```
.
â”œâ”€ guardar.py                   # Script de transformaciÃ³n y guardado
â”œâ”€ proyecto_terremoto.ipynb     # Notebook de anÃ¡lisis y grÃ¡ficos
â”œâ”€ data/                        # (opcional) datasets de entrada
â””â”€ outputs/
   â””â”€ archivo_transformado_normalizado.csv
```

> Si no usas carpetas `data/` y `outputs/`, el script guardarÃ¡ el CSV en el directorio actual.


---

## ğŸš€ Uso rÃ¡pido

### 1) Entorno
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -U pip

# Requerimientos mÃ­nimos
pip install pandas numpy matplotlib seaborn tabulate
```

### 2) Ejecutar (opciÃ³n A: Notebook)
1. Abre `proyecto_terremoto.ipynb` en Jupyter/VS Code.
2. Ejecuta todas las celdas en orden.
3. Revisa el CSV generado y las grÃ¡ficas en la salida del notebook.

### 3) Ejecutar (opciÃ³n B: Script)
- Abre `guardar.py` y **verifica** las rutas/columnas esperadas.
- Ejecuta:
```bash
python guardar.py
```
- Revisa el archivo `archivo_transformado_normalizado.csv` y los *prints* de resumen en consola.


---

## ğŸ” Proceso (pipeline)

1) **Carga y tipificaciÃ³n**
   - ConversiÃ³n de notaciÃ³n cientÃ­fica y **coerciÃ³n** a numÃ©rico (`errors="coerce"`) para asegurar `float` en todas las columnas cuantitativas.
   - EstandarizaciÃ³n de nombres de columnas y verificaciÃ³n de presencia de variables clave (`Mrr`, `Mtt`, `Mpp`, `Mrt`).

2) **TransformaciÃ³n logarÃ­tmica segura**
   - Algunas columnas pueden contener valores **negativos o cero** (p. ej., componentes del tensor de momento).
   - Se calcula un **offset** por columna: `offset = abs(min) + max + 1` para desplazar el rango a valores positivos.
   - Se aplica `log10(valor + offset)` y se **registra el offset** usado por columna para permitir la inversiÃ³n posterior.
   - Se generan nuevas columnas: `Mrr_log`, `Mtt_log`, `Mpp_log`, `Mrt_log`.

3) **ReversiÃ³n de la transformaciÃ³n** (validaciÃ³n)
   - Se implementa `inverse_log_transform`: `10**(col_log) - offset` para volver a la escala original.
   - Se generan columnas de control como `Mrr_reverted`, etc., para verificar consistencia numÃ©rica.

4) **Fecha y orden temporal**
   - A partir de (`year`, `month`, `day`, `hour`, `minute`, `second`) se crea la columna `date` con `pd.to_datetime`.
   - Se ordenan los eventos por `date` para anÃ¡lisis cronolÃ³gico.

5) **Agregaciones anuales**
   - **Magnitud mÃ¡xima por aÃ±o**: `max_magnitude_per_year`.
   - **Magnitud inmediatamente anterior** al evento mÃ¡ximo del aÃ±o (se ordena por fecha y se toma el registro **anterior** al Ã­ndice del mÃ¡ximo).
   - **Conteo de sismos por aÃ±o**: `count`.
   - Se **unen** las tablas por `year` para un *dataset* combinado.

6) **VisualizaciÃ³n**
   - GrÃ¡fico de lÃ­neas para **magnitud mÃ¡xima** y **magnitud anterior** por `year` (seaborn `lineplot`), con leyenda y *grid*.
   - (Opcional) puedes incorporar el **conteo** como eje secundario o grÃ¡ficos adicionales (barras/lÃ­neas).

7) **Salida**
   - Se guarda `archivo_transformado_normalizado.csv` con las columnas originales + `*_log` + `*_reverted` + columnas temporales.
   - Se imprimen **tablas** de muestra (primeras filas) en consola usando `tabulate` (formato `psql`).


---

## âœ… Resultados esperados

- **CSV enriquecido** con transformaciones y campos temporales.  
- **GrÃ¡fica anual** de magnitud mÃ¡xima vs. anterior (inspecciÃ³n visual de extremos).  
- **Resumen tabular** de las primeras filas para verificaciÃ³n rÃ¡pida.


---

## âš ï¸ Notas y limitaciones

- La mÃ©trica â€œ**magnitud anterior al mÃ¡ximo del aÃ±o**â€ depende del **orden temporal**. Verifica que la columna `date` estÃ© correctamente construida y que no existan empates/duplicados que alteren el orden.
- La condiciÃ³n `idxmax > 0` en la bÃºsqueda del evento anterior **asume Ã­ndices consecutivos**: si reseteas Ã­ndices o tienes Ã­ndices no enteros, usa posiciÃ³n (`iloc`) tras ordenar por `date`.
- Si faltan columnas (`Mrr`, etc.), **ajusta** la lista `log_transformed_columns` en el script.
- Para evitar pÃ©rdidas por `coerce`, revisa proporciÃ³n de `NaN` tras la conversiÃ³n numÃ©rica.


---

## ğŸ—ºï¸ Roadmap / mejoras sugeridas

- Persistir **offsets** por columna en un archivo JSON para reproducibilidad fuera de memoria.
- AÃ±adir **tests** rÃ¡pidos (p. ej., confirmar que `reverted â‰ˆ original` dentro de tolerancia).
- Incorporar **anÃ¡lisis de tendencias** (rolling windows) y **detecciÃ³n de outliers**.
- Exportar grÃ¡ficos a `outputs/figures/` en formatos PNG/SVG.


---

## ğŸ“œ Licencia

MIT (o la que definas).

---

### Referencia de cÃ³digo
Parte del pipeline descrito arriba se apoya en utilidades disponibles en los archivos provistos por el usuario. îˆ€fileciteîˆ‚turn1file0îˆ
