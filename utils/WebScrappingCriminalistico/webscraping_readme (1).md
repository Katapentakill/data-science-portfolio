# Web Scraping Antofagasta TV - Automated Data Extraction Project

Este proyecto implementa una soluci√≥n automatizada de web scraping para extraer informaci√≥n de noticias policiales del sitio web de Antofagasta TV utilizando Puppeteer y Node.js. El sistema navega autom√°ticamente por la p√°gina, hace scroll infinito para cargar contenido din√°mico, y extrae datos espec√≠ficos de cada art√≠culo de manera eficiente.

## üß† Descripci√≥n del Proyecto

El proyecto utiliza **Puppeteer** para automatizar la navegaci√≥n web y **t√©cnicas de scraping avanzadas** para extraer informaci√≥n de un sitio web con contenido din√°mico. A trav√©s de scroll autom√°tico, detecci√≥n de nuevos elementos y navegaci√≥n program√°tica, se construye un extractor robusto capaz de recopilar datos de m√∫ltiples p√°ginas de manera automatizada.

## üìä Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|-----------|------------|---------|-----------|
| **Runtime** | Node.js | 14.x+ | Entorno de ejecuci√≥n JavaScript |
| **Web Automation** | Puppeteer | ^19.0.0 | Control program√°tico del navegador |
| **Browser Engine** | Chromium | - | Motor de navegaci√≥n automatizada |
| **Web Standards** | DOM API | - | Manipulaci√≥n de elementos HTML |
| **Async Programming** | ES2017+ | - | Programaci√≥n as√≠ncrona con async/await |
| **Data Structures** | Set | - | Almacenamiento de enlaces √∫nicos |
| **HTTP Protocol** | - | - | Navegaci√≥n y carga de p√°ginas |

## üìÑ Pipeline de Desarrollo

### 1. **Configuraci√≥n e Inicializaci√≥n**
```javascript
const puppeteer = require("puppeteer");

const URL = "https://www.antofagasta.tv/categoria/policial";

const browser = await puppeteer.launch({
  headless: false,  // Modo visible para debugging
});

const page = await browser.newPage();
await page.goto(URL, { waitUntil: "networkidle2" });
```

**Configuraci√≥n principal:**
- **URL objetivo:** Secci√≥n policial de Antofagasta TV
- **Modo headless:** Deshabilitado para monitoreo visual
- **Wait strategy:** NetworkIdle2 para asegurar carga completa
- **Browser instance:** Chromium controlado por Puppeteer

### 2. **Extracci√≥n de Enlaces Din√°micos**

#### Funci√≥n de Detecci√≥n de Enlaces
```javascript
async function getCardLinks(page) {
  return page.evaluate(() => {
    // Selector principal para tarjetas de noticias
    const links = Array.from(document.querySelectorAll(
      ".MuiGrid-root.MuiGrid-item.widget.typography.widget-a0ebd116-8931-4bc4-8e90-5e45a4c60405 a.layerTwo"
    )).map(link => link.href);
    
    // Selector secundario para art√≠culos detallados
    const detailedLinks = Array.from(document.querySelectorAll(
      ".MuiGrid-root.MuiGrid-item.widget.typography.widget-f33bdd76-40cb-413e-945d-1a3599f68b47 a.layerTwo"
    )).map(link => link.href);
    
    return [...links, ...detailedLinks];
  });
}
```

**Estrategia de extracci√≥n:**
- **Selectores m√∫ltiples:** Captura diferentes tipos de tarjetas de noticias
- **Array spreading:** Combinaci√≥n de resultados de m√∫ltiples selectores
- **Link extraction:** Extracci√≥n directa de URLs desde elementos `<a>`
- **DOM evaluation:** Ejecuci√≥n de c√≥digo en el contexto del navegador

### 3. **Scroll Infinito y Carga Din√°mica**

#### Sistema de Scroll Autom√°tico
```javascript
async function autoScrollAndVisitLinks(page) {
  let hasMoreCards = true;
  let visitedLinks = new Set();

  while (hasMoreCards) {
    const links = await getCardLinks(page);

    // Procesar enlaces √∫nicos
    for (const link of links) {
      if (link.startsWith("https://www.antofagasta.tv/categoria/policial/") && 
          !visitedLinks.has(link)) {
        visitedLinks.add(link);
        console.log(`Navegando a: ${link}`);
        await visitLink(page, link);
      }
    }

    // Scroll down con detecci√≥n de nuevo contenido
    hasMoreCards = await page.evaluate(() => {
      const initialHeight = document.body.scrollHeight;
      window.scrollBy(0, window.innerHeight);
      
      return new Promise((resolve) => {
        setTimeout(() => {
          const newHeight = document.body.scrollHeight;
          resolve(newHeight > initialHeight);
        }, 3000); // Buffer de tiempo para carga AJAX
      });
    });
  }
}
```

**Caracter√≠sticas del scroll autom√°tico:**
- **Detecci√≥n de duplicados:** Set para evitar visitas repetidas
- **Validaci√≥n de URL:** Filtrado por categor√≠a espec√≠fica
- **Scroll din√°mico:** Detecci√≥n autom√°tica de nuevo contenido
- **Timeout inteligente:** 3 segundos para carga de contenido AJAX

### 4. **Navegaci√≥n y Extracci√≥n de Datos**

#### Funci√≥n de Visita de Enlaces
```javascript
async function visitLink(page, link) {
  const originalPage = page.url();
  
  // Navegaci√≥n a p√°gina de detalle
  await page.goto(link, { waitUntil: "networkidle2" });
  console.log(`Visit√© la p√°gina: ${link}`);

  // Extracci√≥n de fecha espec√≠fica
  const dateText = await page.evaluate(() => {
    const dateElement = document.querySelector(
      '.MuiTypography-root.MuiTypography-body1.layerOne.date.css-iqx1c8'
    );
    return dateElement ? dateElement.innerText : null;
  });

  console.log(`Fecha encontrada: ${dateText}`);

  // Regreso a p√°gina original
  await page.goto(originalPage, { waitUntil: "networkidle2" });
}
```

**Estrategia de navegaci√≥n:**
- **URL preservation:** Almacenamiento de p√°gina original
- **Data extraction:** Extracci√≥n selectiva de elementos espec√≠ficos
- **Error handling:** Validaci√≥n de existencia de elementos
- **Return navigation:** Regreso autom√°tico a p√°gina principal

## üóÇÔ∏è Estructura del Proyecto

### Archivos y Configuraci√≥n (VS Code Workspace):

```
DATA-SCIENCE-PORTFOLIO/
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ WebScrappingCriminalistico/
        ‚îú‚îÄ‚îÄ node_modules/            # Dependencias instaladas
        ‚îú‚îÄ‚îÄ .gitignore              # Archivos a ignorar en Git
        ‚îú‚îÄ‚îÄ index.js                # Script principal de scraping
        ‚îú‚îÄ‚îÄ package-lock.json       # Lock de versiones exactas
        ‚îú‚îÄ‚îÄ package.json            # Dependencias y scripts de Node.js
        ‚îî‚îÄ‚îÄ README_Puppeteer_Scraper.md  # Documentaci√≥n del proyecto
```

### Configuraci√≥n de package.json (Actual):
```json
{
  "name": "webscrapping-criminalistico",
  "version": "1.0.0",
  "description": "Web scraper para noticias policiales de Antofagasta TV",
  "main": "index.js",
  "scripts": {
    "start": "node index.js",
    "dev": "nodemon index.js"
  },
  "dependencies": {
    "puppeteer": "^19.0.0"
  },
  "devDependencies": {
    "nodemon": "^2.0.20"
  }
}
```

### Archivos de Configuraci√≥n VS Code:
```
.vscode/
‚îú‚îÄ‚îÄ settings.json          # Configuraciones del workspace
‚îú‚îÄ‚îÄ launch.json           # Configuraciones de debugging
‚îî‚îÄ‚îÄ tasks.json            # Tareas automatizadas
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos
```bash
# Verificar versi√≥n de Node.js
node --version  # Debe ser 14.x o superior
npm --version   # Debe ser 6.x o superior
```

### Instalaci√≥n de Dependencias
```bash
# Inicializar proyecto
npm init -y

# Instalar Puppeteer (incluye Chromium)
npm install puppeteer

# Dependencias de desarrollo (opcional)
npm install --save-dev nodemon
```

### Configuraci√≥n del Entorno (Workspace Structure)
```bash
# Navegar al directorio del proyecto
cd data-science-portfolio/utils/WebScrappingCriminalistico

# Verificar archivos del proyecto
ls -la
# index.js
# package.json
# package-lock.json
# node_modules/
# README_Puppeteer_Scraper.md
```

## üõ†Ô∏è C√≥mo Ejecutar el Proyecto

### Ejecuci√≥n en VS Code Workspace
```bash
# Desde el directorio ra√≠z del workspace
cd utils/WebScrappingCriminalistico

# Ejecutar scraper una vez
node index.js

# Ejecutar con debugging en VS Code
# F5 o Run > Start Debugging

# Usar terminal integrado de VS Code
# Ctrl+` para abrir terminal
npm start
```

### Configuraciones Avanzadas

#### Modo Headless (Producci√≥n)
```javascript
const browser = await puppeteer.launch({
  headless: true,          // Ocultar navegador
  args: ['--no-sandbox']   // Para servidores Linux
});
```

#### Configuraci√≥n de Timeouts
```javascript
await page.goto(URL, { 
  waitUntil: "networkidle2",
  timeout: 30000  // 30 segundos m√°ximo
});
```

#### Configuraci√≥n de Viewport
```javascript
await page.setViewport({
  width: 1920,
  height: 1080,
  deviceScaleFactor: 1
});
```

## üìà Funcionalidades Implementadas

### Sistema de Navegaci√≥n Autom√°tica
- **Scroll infinito:** Carga autom√°tica de contenido din√°mico
- **Detecci√≥n de enlaces:** Identificaci√≥n de tarjetas de noticias
- **Navegaci√≥n program√°tica:** Visita autom√°tica de p√°ginas de detalle
- **Control de flujo:** Regreso inteligente a p√°gina principal

### Extracci√≥n de Datos
- **Selectores espec√≠ficos:** Targeting de elementos Material-UI
- **Manejo de estados:** Gesti√≥n de elementos que pueden no existir
- **Logging completo:** Registro de URLs visitadas y datos extra√≠dos
- **Validaci√≥n de contenido:** Verificaci√≥n de estructura esperada

### Optimizaciones de Rendimiento
- **Reutilizaci√≥n de p√°gina:** Una sola instancia para toda la navegaci√≥n
- **Control de memoria:** Gesti√≥n eficiente de recursos del navegador
- **Timeouts inteligentes:** Esperas apropiadas para carga AJAX
- **Deduplicaci√≥n:** Evita procesar enlaces repetidos

## üîß Personalizaci√≥n y Extensiones

### Modificaci√≥n de Selectores
```javascript
// Actualizar selectores para diferentes layouts
const customSelectors = {
  newsCards: ".custom-news-card a",
  dateElement: ".custom-date-selector",
  titleElement: ".custom-title-selector"
};
```

### Extracci√≥n de Datos Adicionales
```javascript
// Funci√≥n extendida para extraer m√°s informaci√≥n
async function extractArticleData(page) {
  return page.evaluate(() => {
    return {
      title: document.querySelector('.title-selector')?.innerText,
      date: document.querySelector('.date-selector')?.innerText,
      content: document.querySelector('.content-selector')?.innerText,
      author: document.querySelector('.author-selector')?.innerText,
      tags: Array.from(document.querySelectorAll('.tag-selector'))
        .map(tag => tag.innerText)
    };
  });
}
```

### Almacenamiento de Datos
```javascript
const fs = require('fs');

// Guardar datos extra√≠dos en JSON
function saveData(data, filename) {
  fs.writeFileSync(
    `./data/${filename}`, 
    JSON.stringify(data, null, 2)
  );
}
```

## üéØ Casos de Uso y Aplicaciones

### Monitoreo de Noticias
- **Alertas autom√°ticas:** Notificaciones de nuevas noticias policiales
- **An√°lisis de tendencias:** Tracking de frecuencia de incidentes
- **Base de datos hist√≥rica:** Archivo de noticias para an√°lisis temporal
- **Dashboard en tiempo real:** Visualizaci√≥n de datos extra√≠dos

### An√°lisis de Contenido
- **Extracci√≥n de patrones:** Identificaci√≥n de tipos de incidentes
- **An√°lisis temporal:** Distribuci√≥n de eventos por fechas/horarios
- **Clasificaci√≥n autom√°tica:** Categorizaci√≥n de noticias por tipo
- **Detecci√≥n de anomal√≠as:** Identificaci√≥n de picos de actividad

### Integraci√≥n con Otros Sistemas
- **APIs REST:** Exposici√≥n de datos extra√≠dos via API
- **Bases de datos:** Almacenamiento en PostgreSQL/MongoDB
- **Sistemas de notificaci√≥n:** Slack, Discord, Email alerts
- **An√°lisis ML:** Input para modelos de procesamiento de texto

## üîç Consideraciones T√©cnicas

### Robustez y Manejo de Errores
```javascript
// Implementaci√≥n de retry logic
async function safePageVisit(page, url, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      await page.goto(url, { waitUntil: "networkidle2" });
      return true;
    } catch (error) {
      console.log(`Intento ${i + 1} fallido: ${error.message}`);
      if (i === maxRetries - 1) throw error;
      await page.waitForTimeout(2000); // Esperar antes de reintentar
    }
  }
}
```

### Optimizaci√≥n de Memoria
```javascript
// Limpieza peri√≥dica de memoria
async function clearBrowserMemory(page) {
  await page.evaluate(() => {
    // Limpiar cache del navegador
    if ('caches' in window) {
      caches.keys().then(names => {
        names.forEach(name => caches.delete(name));
      });
    }
  });
}
```

### Rate Limiting y √âtica
```javascript
// Implementar delays para ser respetuoso con el servidor
const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

// Usar entre requests
await delay(1000); // 1 segundo entre requests
```

## üéØ Mejoras Futuras

### Funcionalidades Avanzadas
1. **Scraping distribuido:** M√∫ltiples instancias paralelas
2. **Detecci√≥n de cambios:** Monitoring de actualizaciones de contenido
3. **Clasificaci√≥n autom√°tica:** ML para categorizar noticias
4. **An√°lisis de sentimiento:** Procesamiento NLP del contenido

### Infraestructura
1. **Containerizaci√≥n:** Docker para deployment
2. **Scheduling:** Cron jobs para ejecuci√≥n peri√≥dica
3. **Monitoring:** M√©tricas de performance y errores
4. **Escalabilidad:** Cluster de scrapers distribuidos

### Integraci√≥n de Datos
1. **Data pipelines:** ETL autom√°tico hacia data warehouses
2. **APIs GraphQL:** Interface flexible para consultas
3. **Real-time streaming:** WebSockets para datos en vivo
4. **Machine Learning:** Modelos predictivos sobre los datos

## ‚öñÔ∏è Consideraciones Legales y √âticas

### T√©rminos de Servicio
- **Revisar robots.txt:** Verificar pol√≠ticas de scraping del sitio
- **Rate limiting:** Implementar delays apropiados
- **User-Agent:** Identificaci√≥n transparente del bot
- **Respeto al ancho de banda:** Evitar sobrecarga del servidor

### Buenas Pr√°cticas
```javascript
// Configurar User-Agent identificable
await page.setUserAgent('AntofagastaTV-Scraper/1.0 (+contacto@example.com)');

// Implementar delays entre requests
const DELAY_BETWEEN_REQUESTS = 2000; // 2 segundos

// Respetar se√±ales de stop del servidor
if (response.status() === 429) { // Too Many Requests
  await delay(60000); // Esperar 1 minuto
}
```

## üìû Contacto y Colaboraci√≥n

Para consultas t√©cnicas, colaboraciones en proyectos de web scraping, automatizaci√≥n web, o implementaci√≥n de sistemas de monitoreo de noticias, no dudes en contactar.

## üìó Referencias y Recursos

- **Puppeteer Documentation:** Gu√≠a oficial y API reference
- **Web Scraping Best Practices:** T√©cnicas √©ticas y eficientes
- **CSS Selectors:** Documentaci√≥n de selectores avanzados
- **Node.js Async Patterns:** Programaci√≥n as√≠ncrona avanzada

---

*Este proyecto representa una implementaci√≥n robusta de web scraping automatizado utilizando tecnolog√≠as modernas de Node.js y Puppeteer, dise√±ado para extraer informaci√≥n de manera eficiente y √©tica desde sitios web con contenido din√°mico, proporcionando una base s√≥lida para sistemas de monitoreo y an√°lisis de noticias.*