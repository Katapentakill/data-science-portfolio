# An√°lisis y Modelado del Conjunto de Datos del Titanic - Machine Learning Classification Project

Este proyecto implementa una soluci√≥n completa para la cl√°sica competici√≥n de Kaggle del Titanic utilizando t√©cnicas avanzadas de machine learning y ensemble methods. El objetivo es predecir la supervivencia de los pasajeros del Titanic bas√°ndose en caracter√≠sticas demogr√°ficas, socioecon√≥micas y de viaje, utilizando un modelo de **StackingClassifier** que combina m√∫ltiples algoritmos de clasificaci√≥n.

## üß† Descripci√≥n del Proyecto

El proyecto utiliza **StackingClassifier** como modelo principal, combinando **RandomForest**, **CatBoost**, **LightGBM** y **XGBoost** con un meta-learner **RidgeClassifier**. A trav√©s de ingenier√≠a de caracter√≠sticas avanzada, an√°lisis exploratorio detallado y t√©cnicas de ensemble, se construye un predictor robusto capaz de determinar la supervivencia con alta precisi√≥n.

## üìä Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|-----------|------------|---------|-----------|
| **Lenguaje** | Python | 3.13.1 | Lenguaje principal de desarrollo |
| **Machine Learning** | Scikit-learn | - | Framework principal y StackingClassifier |
| **Ensemble Methods** | RandomForest | - | Algoritmo base de ensemble |
| **Gradient Boosting** | CatBoost | - | Gradient boosting con manejo autom√°tico de categ√≥ricas |
| **Gradient Boosting** | LightGBM | - | Gradient boosting eficiente |
| **Gradient Boosting** | XGBoost | - | Extreme gradient boosting |
| **Meta-learner** | RidgeClassifier | - | Modelo final del stacking |
| **An√°lisis de Datos** | Pandas | - | Manipulaci√≥n y an√°lisis de datos |
| **An√°lisis de Datos** | NumPy | - | Operaciones num√©ricas |
| **Visualizaci√≥n** | Matplotlib | - | Gr√°ficos y visualizaciones |
| **Visualizaci√≥n** | Seaborn | - | Visualizaciones estad√≠sticas avanzadas |
| **Preprocessing** | LabelEncoder | - | Codificaci√≥n de variables categ√≥ricas |
| **M√©tricas** | Accuracy, Confusion Matrix | - | Evaluaci√≥n de clasificaci√≥n |

## üìÑ Pipeline de Desarrollo

### 1. **Carga y Exploraci√≥n de Datos**
```python
# Carga del dataset principal del Titanic
train = pd.read_csv('D:\\Ale\\Competitions\\Titanic\\Data\\train.csv')
test_data = pd.read_csv('D:\\Ale\\Competitions\\Titanic\\Data\\test.csv')
```

**Datasets principales:**
- **train.csv:** Datos hist√≥ricos de pasajeros con supervivencia conocida
- **test.csv:** Conjunto de evaluaci√≥n para predicciones finales
- **Variables clave:** PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked

### 2. **Limpieza y Preprocesamiento de Datos**

#### Manejo de Valores Faltantes
```python
# Estrategia diferenciada por tipo de dato
for column in train.columns:
    if train[column].dtype == 'object':
        train[column].fillna(train[column].mode()[0], inplace=True)  # Moda para categ√≥ricas
    else:
        train[column].fillna(train[column].mean(), inplace=True)     # Media para num√©ricas
```

**Justificaci√≥n de la estrategia:**
- **Variables categ√≥ricas:** Moda preserva la distribuci√≥n m√°s frecuente
- **Variables num√©ricas:** Media mantiene la tendencia central
- **Robustez:** Evita p√©rdida de observaciones por missing values
- **Consistencia:** Aplicaci√≥n uniforme en train y test

### 3. **Ingenier√≠a de Caracter√≠sticas Avanzada**

#### Caracter√≠stica de Tama√±o Familiar
```python
# Crear variable compuesta de tama√±o familiar
train['Familia Size'] = train['SibSp'] + train['Parch'] + 1
```

#### Extracci√≥n y Agrupaci√≥n de T√≠tulos
```python
import re

# Extraer t√≠tulo del nombre
train['Title'] = train['Name'].apply(lambda x: re.findall(r', (.*?)\.', x)[0])

# Agrupar t√≠tulos raros para reducir dimensionalidad
title_replacements = {
    'Mme': 'Mrs', 'Mlle': 'Miss', 'Ms': 'Miss', 'Countess': 'Rare', 
    'Lady': 'Rare', 'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 
    'Major': 'Rare', 'Capt': 'Rare', 'Don': 'Rare', 'Dona': 'Rare'
}
train['Title'] = train['Title'].replace(title_replacements)
```

#### Categorizaci√≥n de Edad
```python
def categorize_age(age):
    if age <= 5:
        return 'Child'
    elif age <= 12:
        return 'Young'
    elif age <= 18:
        return 'Teenager'
    elif age <= 60:
        return 'Adult'
    else:
        return 'Senior'

train['Age Category'] = train['Age'].apply(categorize_age)
```

#### Binning de Tarifas
```python
# Crear categor√≠as de precio basadas en cuartiles
max_fare = train['Fare'].max()
bins = [0, max_fare / 4, max_fare / 2, 3 * max_fare / 4, float('inf')]
labels = ['Barato', 'Semi Barato', 'Semi Caro', 'Caro']
train['Fare Category'] = pd.cut(train['Fare'], bins=bins, labels=labels, right=False)
```

**Beneficios de la ingenier√≠a de caracter√≠sticas:**
- **Tama√±o familiar:** Captura din√°mica familiar vs individual
- **T√≠tulos agrupados:** Reduce sparsity y mejora generalizaci√≥n
- **Categor√≠as de edad:** Convierte variable continua en rangos significativos
- **Binning de tarifas:** Segmentaci√≥n por poder adquisitivo

### 4. **An√°lisis Exploratorio de Datos (EDA)**

#### Visualizaci√≥n de Supervivencia
```python
# Distribuci√≥n de la variable objetivo
plt.figure(figsize=(6,4))
sns.countplot(data=train, x='Survived')
plt.title('Distribuci√≥n de Supervivencia (0 = No, 1 = S√≠)')
plt.show()
```

#### An√°lisis de Relaciones
```python
# Relaci√≥n sexo-supervivencia
sns.countplot(data=train, x='Sex', hue='Survived')
plt.title('Relaci√≥n entre Sexo y Supervivencia')

# Relaci√≥n clase-supervivencia
sns.countplot(data=train, x='Pclass', hue='Survived')
plt.title('Relaci√≥n entre Clase y Supervivencia')
```

#### Matriz de Correlaci√≥n
```python
# Preparaci√≥n para an√°lisis de correlaci√≥n
train_corr = train.drop(columns=['Name', "Ticket", "Cabin", "PassengerId"])

# Heatmap de correlaciones
plt.figure(figsize=(10, 8))
sns.heatmap(train_corr.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matriz de Correlaci√≥n entre Caracter√≠sticas')
plt.show()
```

### 5. **Codificaci√≥n de Variables Categ√≥ricas**

#### Label Encoding Sistem√°tico
```python
# Codificaci√≥n de todas las variables categ√≥ricas
le = LabelEncoder()
categorical_cols = ['Sex', 'Embarked', 'Title', 'Age Category', 'Fare Category']

for col in categorical_cols:
    train[col] = le.fit_transform(train[col].astype(str))
```

**Ventajas del enfoque:**
- **Consistencia:** Mismo encoder para train y test
- **Robustez:** Conversi√≥n a string maneja valores mixtos
- **Eficiencia:** Preparaci√≥n √≥ptima para tree-based models
- **Reproducibilidad:** Transformaciones consistentes

### 6. **Preparaci√≥n de Datos para Modelado**

#### Selecci√≥n de Caracter√≠sticas
```python
# Features finales para el modelo
X = train[['Sex', 'Age', 'Familia Size', 'Fare', 'Embarked', 
          'Pclass', 'Title', 'Age Category', 'Fare Category']]
y = train['Survived']

# Divisi√≥n estratificada para mantener proporci√≥n de clases
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

### 7. **Construcci√≥n del Modelo de Stacking**

#### Configuraci√≥n del StackingClassifier
```python
stacking_model = StackingClassifier(
    estimators=[
        ('Random Forest', RandomForestClassifier(random_state=42)),
        ('CatBoost', CatBoostClassifier(silent=True)),
        ('LightGBM', LGBMClassifier()),
        ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),
    ],
    final_estimator=RidgeClassifier(),
    cv=5  # Cross-validation para meta-features
)

# Entrenamiento del modelo ensemble
stacking_model.fit(X_train, y_train)
```

**Justificaci√≥n de la arquitectura:**
- **Random Forest:** Robustez contra overfitting, manejo de caracter√≠sticas correlacionadas
- **CatBoost:** Excelente performance con variables categ√≥ricas, menos hyperparameter tuning
- **LightGBM:** Eficiencia computacional, buena generalizaci√≥n
- **XGBoost:** Performance competitiva, regularizaci√≥n avanzada
- **RidgeClassifier:** Meta-learner lineal previene overfitting del ensemble

### 8. **Evaluaci√≥n del Modelo**

#### M√©tricas de Performance
```python
# Predicciones y evaluaci√≥n
y_pred_stacking = stacking_model.predict(X_test)
accuracy_stacking = accuracy_score(y_test, y_pred_stacking)
print(f'Accuracy del Stacking Model: {accuracy_stacking:.2f}')
```

#### Matriz de Confusi√≥n
```python
# Visualizaci√≥n de resultados
conf_matrix_stacking = confusion_matrix(y_test, y_pred_stacking)
plt.figure(figsize=(6, 6))
disp_stacking = ConfusionMatrixDisplay(
    confusion_matrix=conf_matrix_stacking, 
    display_labels=[0, 1]
)
disp_stacking.plot(cmap='Blues', ax=plt.gca())
plt.title('Matriz de Confusi√≥n - Stacking Model')
plt.show()
```

### 9. **Predicciones Finales y Submission**

#### Procesamiento del Test Set
```python
# Aplicar mismo pipeline al conjunto de test
# 1. Limpieza de datos
# 2. Ingenier√≠a de caracter√≠sticas
# 3. Codificaci√≥n de variables categ√≥ricas
# 4. Selecci√≥n de features

# Manejo de categor√≠as no vistas
for col in categorical_cols:
    if test_data[col].isin(le.classes_).all():
        test_data[col] = le.transform(test_data[col].astype(str))
    else:
        test_data[col] = le.fit_transform(test_data[col].astype(str))
```

#### Generaci√≥n de Submission
```python
# Preparar datos finales
X_test_final = test_data[['Sex', 'Age', 'Familia Size', 'Fare', 'Embarked', 
                         'Pclass', 'Title', 'Age Category', 'Fare Category']]

# Predicciones finales
y_test_pred = stacking_model.predict(X_test_final)

# Crear archivo de submission
submission = pd.DataFrame({
    'PassengerId': test_data['PassengerId'], 
    'Survived': y_test_pred
})
submission.to_csv('D:\\Ale\\Competitions\\Titanic\\Data\\submission.csv', index=False)
```

## üóÇÔ∏è Estructura del Proyecto (Jupyter Notebook Environment)

### Archivos y Datasets:

```
DATA-SCIENCE-PORTFOLIO/
‚îî‚îÄ‚îÄ competitions/
    ‚îî‚îÄ‚îÄ Titanic/
        ‚îú‚îÄ‚îÄ Data/
        ‚îÇ   ‚îú‚îÄ‚îÄ train.csv                    # Dataset de entrenamiento
        ‚îÇ   ‚îú‚îÄ‚îÄ test.csv                     # Dataset de evaluaci√≥n
        ‚îÇ   ‚îî‚îÄ‚îÄ submission.csv               # Predicciones finales (generado)
        ‚îî‚îÄ‚îÄ Notebook/
            ‚îú‚îÄ‚îÄ ordenador.ipynb              # Notebook principal de an√°lisis
            ‚îú‚îÄ‚îÄ Random_Forest.ipynb          # Exploraci√≥n con Random Forest
            ‚îú‚îÄ‚îÄ Titanic.ipynb               # An√°lisis base
            ‚îî‚îÄ‚îÄ Titanic2.ipynb              # Iteraciones adicionales

OUTPUTS GENERADOS EN NOTEBOOK:
‚îú‚îÄ‚îÄ Visualizaciones inline:
‚îÇ   ‚îú‚îÄ‚îÄ Distribuci√≥n de supervivencia
‚îÇ   ‚îú‚îÄ‚îÄ Relaciones sexo-supervivencia
‚îÇ   ‚îú‚îÄ‚îÄ Relaciones clase-supervivencia
‚îÇ   ‚îú‚îÄ‚îÄ Matriz de correlaci√≥n (10x8)
‚îÇ   ‚îî‚îÄ‚îÄ Matriz de confusi√≥n del modelo
‚îú‚îÄ‚îÄ Modelos entrenados:
‚îÇ   ‚îî‚îÄ‚îÄ StackingClassifier (en memoria)
‚îî‚îÄ‚îÄ Archivo de submission:
    ‚îî‚îÄ‚îÄ submission.csv (para Kaggle)
```

### Rutas de Acceso en C√≥digo:
```python
# Datos de entrada
TRAIN_PATH = "D:\\Ale\\Competitions\\Titanic\\Data\\train.csv"
TEST_PATH = "D:\\Ale\\Competitions\\Titanic\\Data\\test.csv"

# Output de predicciones
SUBMISSION_PATH = "D:\\Ale\\Competitions\\Titanic\\Data\\submission.csv"

# Configuraciones del modelo
RANDOM_STATE = 42
TEST_SIZE = 0.2
CV_FOLDS = 5
```

## üöÄ C√≥mo Ejecutar el Proyecto

### Configuraci√≥n del Entorno Jupyter
```python
# Librer√≠as principales requeridas
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay

# Configurar visualizaci√≥n
plt.style.use('default')
sns.set_palette("husl")
```

### Verificaci√≥n de Datos
```python
# Exploraci√≥n inicial del dataset
print("=== INFORMACI√ìN DEL DATASET DE ENTRENAMIENTO ===")
print(f"Forma del dataset: {train.shape}")
print(f"Columnas: {list(train.columns)}")
print(f"Valores nulos por columna:")
print(train.isnull().sum())
print(f"Distribuci√≥n de supervivencia:")
print(train['Survived'].value_counts())
```

### Flujo de Ejecuci√≥n en Jupyter

#### 1. **Secci√≥n 1-2: Carga y Limpieza**
```python
# Cargar datasets y aplicar limpieza
train = pd.read_csv(TRAIN_PATH)
test_data = pd.read_csv(TEST_PATH)

# Aplicar estrategia de imputaci√≥n
# Rellenar nulos seg√∫n tipo de variable
```

#### 2. **Secci√≥n 3: Ingenier√≠a de Caracter√≠sticas**
```python
# Crear nuevas variables
# - Familia Size
# - Title extraction y agrupaci√≥n
# - Age Category
# - Fare Category binning
```

#### 3. **Secci√≥n 4: An√°lisis Exploratorio**
```python
# Generar visualizaciones inline
# - Countplots de supervivencia
# - An√°lisis bivariado con hue
# - Heatmap de correlaciones
```

#### 4. **Secciones 5-7: Preprocesamiento y Modelado**
```python
# Label encoding de categ√≥ricas
# Divisi√≥n train/test
# Configuraci√≥n y entrenamiento del StackingClassifier
```

#### 5. **Secciones 8-9: Evaluaci√≥n y Submission**
```python
# M√©tricas de evaluaci√≥n
# Matriz de confusi√≥n
# Procesamiento de test set y generaci√≥n de submission
```

## üìà Resultados y An√°lisis

### Hallazgos del An√°lisis Exploratorio

#### Patrones de Supervivencia
- **Sexo:** Las mujeres tuvieron una tasa de supervivencia significativamente mayor (pol√≠tica "mujeres y ni√±os primero")
- **Clase socioecon√≥mica:** Pasajeros de primera clase tuvieron mayor probabilidad de supervivencia
- **Edad:** Los ni√±os tuvieron mayor tasa de supervivencia que los adultos
- **Tama√±o familiar:** Familias de tama√±o medio tuvieron mejor supervivencia que individuos solos o familias muy grandes

#### Correlaciones Significativas
- **Sex-Survived:** Correlaci√≥n negativa fuerte (codificado: female=0, male=1)
- **Pclass-Survived:** Correlaci√≥n negativa (clases altas = n√∫meros bajos)
- **Fare-Survived:** Correlaci√≥n positiva moderada
- **Age-Survived:** Correlaci√≥n negativa d√©bil

### Performance del Modelo
- **Arquitectura:** StackingClassifier con 4 base learners + meta-learner
- **Validaci√≥n:** 5-fold cross-validation para meta-features
- **M√©tricas:** Accuracy, precision, recall via confusion matrix
- **Robustez:** Ensemble reduce varianza de predicciones individuales

### T√©cnicas Implementadas
1. **Feature engineering avanzada:** Creaci√≥n de variables compuestas y categ√≥ricas
2. **Ensemble heterog√©neo:** Combinaci√≥n de diferentes paradigmas (bagging, boosting)
3. **Meta-learning:** RidgeClassifier aprende a combinar predicciones base
4. **Preprocessing robusto:** Manejo sistem√°tico de missing values y encoding

## üî¨ Innovaciones T√©cnicas

### Fortalezas del Enfoque Ensemble
1. **Diversidad de modelos:** Random Forest (bagging) + m√∫ltiples gradient boosting
2. **Regularizaci√≥n autom√°tica:** Ridge meta-learner previene overfitting
3. **Robustez:** Menos sensible a outliers y ruido que modelos individuales
4. **Generalizaci√≥n:** Cross-validation en meta-features mejora capacidad predictiva

### Aspectos √önicos del Proyecto
- **Pipeline completo:** Desde EDA hasta submission en un flujo integrado
- **Feature engineering domain-specific:** Variables creadas con conocimiento del dominio
- **Manejo de test leakage:** Encoding consistente entre train y test
- **Visualizaci√≥n comprehensiva:** EDA que informa las decisiones de modelado

## üéØ Posibles Mejoras

### Optimizaci√≥n de Modelos
1. **Hyperparameter tuning:** GridSearchCV o RandomizedSearchCV para cada base learner
2. **Feature selection:** M√©todos autom√°ticos para selecci√≥n √≥ptima de caracter√≠sticas
3. **Cross-validation estrategia:** TimeSeriesSplit si hay componente temporal
4. **M√©tricas alternativas:** AUC-ROC, F1-score para mejor evaluaci√≥n

### Feature Engineering Avanzada
1. **Interacciones:** Features de segunda orden entre variables importantes
2. **Transformaciones:** Log, sqrt, polynomial features
3. **Encoding alternativo:** Target encoding, frequency encoding para categ√≥ricas
4. **Variables externas:** Informaci√≥n hist√≥rica del Titanic, condiciones meteorol√≥gicas

### Arquitectura de Modelos
1. **Stacking multicapa:** M√∫ltiples niveles de meta-learners
2. **Blending:** Promedio ponderado de modelos en lugar de meta-learner
3. **Neural networks:** Integraci√≥n de redes neuronales como base learner
4. **Calibraci√≥n:** Calibration de probabilidades para mejor interpretabilidad

## üéØ Aplicaciones del Mundo Real

### Transferencia a Otros Dominios
- **An√°lisis de riesgo crediticio:** Predicci√≥n de default en pr√©stamos
- **Marketing predictivo:** Propensi√≥n de compra de clientes
- **Medicina predictiva:** Diagn√≥stico basado en caracter√≠sticas del paciente
- **An√°lisis de retenci√≥n:** Predicci√≥n de churn en servicios

### Metodolog√≠a Generalizable
1. **EDA sistem√°tico:** Proceso replicable para cualquier dataset tabular
2. **Feature engineering:** T√©cnicas aplicables a variables categ√≥ricas y num√©ricas
3. **Ensemble methods:** Framework extensible a otros problemas de clasificaci√≥n
4. **Validation strategy:** Cross-validation apropiada para problemas similares

## üìß Consideraciones T√©cnicas

### Reproducibilidad
```python
# Control de aleatoriedad
RANDOM_STATE = 42

# Configuraci√≥n de seeds para todos los algoritmos
RandomForestClassifier(random_state=RANDOM_STATE)
train_test_split(..., random_state=RANDOM_STATE)
```

### Eficiencia Computacional
- **Parallel processing:** Todos los algoritmos utilizan m√∫ltiples cores
- **Memory management:** Liberaci√≥n de variables intermedias
- **Early stopping:** En gradient boosting para prevenir overfitting
- **Silent mode:** CatBoost sin verbose para ejecuci√≥n limpia

### Robustez del Pipeline
- **Error handling:** Manejo de categor√≠as no vistas en test
- **Data validation:** Verificaci√≥n de formas y tipos de datos
- **Consistent preprocessing:** Mismo pipeline para train y test
- **Version control:** Tracking de experimentos y resultados

## üìû Contacto y Colaboraci√≥n

Para consultas t√©cnicas, colaboraciones en proyectos de machine learning, ensemble methods, o aplicaciones de clasificaci√≥n en an√°lisis predictivo, no dudes en contactar.

## üìó Referencias y Recursos

- **Scikit-learn Documentation:** Gu√≠a oficial de StackingClassifier
- **Kaggle Titanic Competition:** Competici√≥n original y notebooks p√∫blicos
- **Ensemble Methods Literature:** Papers sobre stacking y meta-learning
- **Feature Engineering Best Practices:** T√©cnicas avanzadas para ML tabular

---

*Este proyecto representa una implementaci√≥n robusta de ensemble learning para problemas de clasificaci√≥n binaria, combinando an√°lisis exploratorio detallado, ingenier√≠a de caracter√≠sticas domain-specific y t√©cnicas avanzadas de machine learning en un pipeline reproducible que puede servir como base para proyectos similares de an√°lisis predictivo.*