# House Prices Prediction - Kaggle Competition Solution

Este proyecto implementa una soluci√≥n completa para la competici√≥n de Kaggle "House Prices: Advanced Regression Techniques" utilizando t√©cnicas avanzadas de regresi√≥n y aprendizaje autom√°tico. El objetivo es predecir con precisi√≥n los precios de venta de propiedades residenciales bas√°ndose en 79 caracter√≠sticas descriptivas.

## üè† Descripci√≥n del Proyecto

El proyecto utiliza el dataset "House Prices: Advanced Regression Techniques" de Kaggle, que contiene informaci√≥n detallada sobre propiedades residenciales en Ames, Iowa. A trav√©s de un proceso exhaustivo de an√°lisis exploratorio de datos, preprocesamiento y modelado, se construye un sistema predictivo robusto.

## üìä Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|-----------|------------|---------|-----------|
| **Lenguaje** | Python | 3.x | Lenguaje principal de desarrollo |
| **An√°lisis de Datos** | Pandas | - | Manipulaci√≥n y an√°lisis de datos |
| **An√°lisis de Datos** | NumPy | - | Operaciones num√©ricas y matrices |
| **Machine Learning** | Scikit-learn | - | Algoritmos de ML y preprocesamiento |
| **Machine Learning** | XGBoost | - | Gradient boosting avanzado |
| **Machine Learning** | LightGBM | - | Gradient boosting eficiente |
| **Machine Learning** | CatBoost | - | Manejo de caracter√≠sticas categ√≥ricas |
| **Visualizaci√≥n** | Matplotlib | - | Gr√°ficos y visualizaciones b√°sicas |
| **Visualizaci√≥n** | Seaborn | - | Visualizaciones estad√≠sticas avanzadas |
| **Interpretabilidad** | SHAP | - | Explicabilidad del modelo |
| **Utilidades** | Tabulate | - | Formateo de tablas para output |

## üîÑ Proceso de Desarrollo

### 1. **Carga y Exploraci√≥n de Datos**
- Importaci√≥n de datasets de entrenamiento y prueba
- An√°lisis inicial de la estructura de datos
- Identificaci√≥n de tipos de datos (num√©ricos, categ√≥ricos, string)

### 2. **An√°lisis de Valores Nulos**
- Funci√≥n personalizada `null_percentage_with_type()` para identificar patrones de valores faltantes
- An√°lisis del porcentaje de nulos por columna
- Clasificaci√≥n por tipo de dato para estrategias de imputaci√≥n diferenciadas

### 3. **Limpieza de Datos - Fase 1**
**Eliminaci√≥n de columnas con alta proporci√≥n de nulos:**
- `PoolQC`, `MiscFeature`, `Alley`, `Fence`, `MasVnrType`, `FireplaceQu`

**Estrategias de imputaci√≥n:**
- **KNN Imputation** para variables num√©ricas: `MasVnrArea`, `GarageYrBlt`, `LotFrontage`
- **Imputaci√≥n por moda** para variables categ√≥ricas: caracter√≠sticas de garaje, s√≥tano y sistema el√©ctrico

### 4. **An√°lisis de Variabilidad**
- Funci√≥n `count_unique_variations()` para analizar la diversidad de valores categ√≥ricos
- Identificaci√≥n de caracter√≠sticas con poca variabilidad informativa

### 5. **Limpieza de Datos - Fase 2**
**Eliminaci√≥n de caracter√≠sticas con baja variabilidad:**
- `Utilities`, `Street`, `LandSlope`, `Condition2`, `RoofMatl`

### 6. **Ingenier√≠a de Caracter√≠sticas**
- **Codificaci√≥n de variables categ√≥ricas** usando `LabelEncoder`
- **An√°lisis de correlaci√≥n** mediante matriz de correlaci√≥n visual
- **Filtrado por correlaci√≥n**: eliminaci√≥n de caracter√≠sticas con correlaci√≥n < 0.10 o negativa con la variable objetivo

### 7. **Preparaci√≥n del Modelo**
- **Transformaci√≥n logar√≠tmica** de la variable objetivo (`SalePrice`) usando `np.log1p()`
- **Divisi√≥n train-test** con proporci√≥n 80-20
- **Selecci√≥n del modelo principal**: CatBoost con hiperpar√°metros optimizados

### 8. **Modelado y Evaluaci√≥n**
**Configuraci√≥n de CatBoost:**
```python
best_params = {
    'learning_rate': 0.03,
    'l2_leaf_reg': 3,
    'iterations': 1000,
    'depth': 4,
    'bagging_temperature': 1,
    'random_state': 42
}
```

**M√©trica de evaluaci√≥n:** RMSE (Root Mean Square Error)

### 9. **Meta-Modelado (Stacking)**
- Implementaci√≥n de stacking con Ridge Regression como meta-modelo
- Combinaci√≥n de predicciones de m√∫ltiples modelos base
- Mejora de la robustez y precisi√≥n predictiva

### 10. **Procesamiento del Conjunto de Prueba**
- Aplicaci√≥n de las mismas transformaciones al conjunto de prueba
- Manejo de valores nulos espec√≠ficos del conjunto de test
- Generaci√≥n de predicciones finales

### 11. **Generaci√≥n de Resultados**
- Transformaci√≥n inversa de predicciones (`np.expm1()`)
- Creaci√≥n del archivo de submission en formato CSV
- Formato compatible con Kaggle: `Id`, `SalePrice`

## üìÅ Estructura del Proyecto

Este proyecto fue desarrollado completamente en **Kaggle Notebooks**, por lo que toda la implementaci√≥n se encuentra en un √∫nico notebook:

```
House Prices - Kaggle Competition/
‚îÇ
‚îú‚îÄ‚îÄ house-prices-analysis.ipynb     # Notebook principal con todo el an√°lisis
‚îú‚îÄ‚îÄ /kaggle/input/
‚îÇ   ‚îú‚îÄ‚îÄ train.csv                   # Dataset de entrenamiento (1460 filas)
‚îÇ   ‚îú‚îÄ‚îÄ test.csv                    # Dataset de prueba (1459 filas)
‚îÇ   ‚îî‚îÄ‚îÄ data_description.txt        # Descripci√≥n de las caracter√≠sticas
‚îÇ
‚îî‚îÄ‚îÄ /kaggle/working/
    ‚îî‚îÄ‚îÄ submission.csv              # Predicciones finales para Kaggle
```

**Estructura del Notebook:**
- **Celdas 1-2**: Importaci√≥n de librer√≠as y carga de datos
- **Celdas 3-8**: An√°lisis y limpieza de valores nulos
- **Celdas 9-12**: Eliminaci√≥n de caracter√≠sticas con baja variabilidad
- **Celdas 13-15**: An√°lisis de correlaci√≥n y filtrado de caracter√≠sticas
- **Celdas 16-18**: Entrenamiento y evaluaci√≥n del modelo
- **Celdas 19-25**: Procesamiento del conjunto de prueba y generaci√≥n de submissions

## üöÄ C√≥mo Ejecutar el Proyecto

### Opci√≥n 1: Kaggle (Recomendado)
1. Accede al notebook en Kaggle: [House Prices - Advanced Regression Techniques](kaggle.com/code/username/house-prices)
2. Haz clic en "Copy and Edit" para crear tu propia versi√≥n
3. Ejecuta todas las celdas secuencialmente
4. El archivo `submission.csv` se generar√° autom√°ticamente en `/kaggle/working/`

### Opci√≥n 2: Entorno Local
```bash
# Instalar dependencias
pip install numpy pandas scikit-learn xgboost lightgbm catboost matplotlib seaborn shap tabulate

# Descargar el dataset desde Kaggle
kaggle competitions download -c house-prices-advanced-regression-techniques

# Ejecutar el notebook
jupyter notebook house_prices_analysis.ipynb
```

**Nota:** El c√≥digo est√° optimizado para el entorno Kaggle con rutas espec√≠ficas (`/kaggle/input/`, `/kaggle/working/`)

## üìà Resultados y M√©tricas

El modelo final utiliza un enfoque de stacking que combina:
- **CatBoost** como modelo base principal
- **Ridge Regression** como meta-modelo

**M√©tricas de rendimiento:**
- RMSE en entrenamiento: [valor espec√≠fico del modelo]
- RMSE en validaci√≥n: [valor espec√≠fico del modelo]

## üîç Caracter√≠sticas Clave del Enfoque

### Fortalezas
1. **Manejo robusto de valores nulos** con estrategias diferenciadas
2. **Selecci√≥n de caracter√≠sticas basada en correlaci√≥n**
3. **Transformaciones apropiadas** (logar√≠tmica para variable objetivo)
4. **Meta-modelado** para mejorar generalizaci√≥n
5. **Visualizaciones comprehensivas** para an√°lisis exploratorio

### Innovaciones T√©cnicas
- Funci√≥n personalizada para an√°lisis de nulos con tipado
- Pipeline de limpieza reproducible
- An√°lisis de variabilidad categ√≥rica
- Stacking simplificado pero efectivo

## üéØ Posibles Mejoras

1. **Validaci√≥n cruzada** para evaluaci√≥n m√°s robusta
2. **Optimizaci√≥n de hiperpar√°metros** automatizada (Grid/Random Search)
3. **Ensemble m√°s diverso** incluyendo modelos lineales y tree-based
4. **Feature engineering avanzado** (interacciones, polinomios)
5. **Manejo de outliers** m√°s sofisticado

## üìù Notas de Implementaci√≥n

- **Desarrollado completamente en Kaggle Notebooks** para facilitar la reproducibilidad
- **Dataset integrado**: utiliza directamente los datos de la competici√≥n de Kaggle
- **Rutas optimizadas**: c√≥digo adaptado al sistema de archivos de Kaggle (`/kaggle/input/`, `/kaggle/working/`)
- **Ejecuci√≥n secuencial**: las celdas deben ejecutarse en orden para mantener dependencias
- **Reproducibilidad garantizada**: `random_state=42` en todos los componentes aleatorios
- **Salida directa**: el archivo de submission se genera autom√°ticamente para env√≠o a Kaggle

## üìû Contacto

Para preguntas, sugerencias o colaboraciones, no dudes en contactar.

---

*Este proyecto fue desarrollado como parte de la competici√≥n "House Prices: Advanced Regression Techniques" en Kaggle.*