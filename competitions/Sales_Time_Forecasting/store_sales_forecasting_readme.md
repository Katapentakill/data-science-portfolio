# Predicci√≥n de Ventas de Tiendas con CatBoost - Machine Learning Time Series Project

Este proyecto implementa una soluci√≥n completa para la competici√≥n de Kaggle "Store Sales - Time Series Forecasting" utilizando t√©cnicas avanzadas de machine learning y el algoritmo CatBoost. El objetivo es predecir las ventas de productos en diferentes tiendas utilizando datos hist√≥ricos, informaci√≥n de transacciones, precios del petr√≥leo, d√≠as festivos y caracter√≠sticas de las tiendas.

## üß† Descripci√≥n del Proyecto

El proyecto utiliza **CatBoost Regressor** como modelo principal para realizar predicciones de series temporales en un contexto de retail. A trav√©s de ingenier√≠a de caracter√≠sticas temporales, fusi√≥n de m√∫ltiples fuentes de datos y transformaciones logar√≠tmicas, se construye un predictor robusto capaz de estimar las ventas futuras con alta precisi√≥n.

## üìä Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|-----------|------------|---------|-----------|
| **Lenguaje** | Python | 3.x | Lenguaje principal de desarrollo |
| **Machine Learning** | CatBoost | - | Algoritmo principal de regresi√≥n |
| **ML Complementario** | XGBoost | - | Modelo de ensemble (preparado) |
| **ML Tradicional** | Scikit-learn | - | Ridge regression y m√©tricas |
| **An√°lisis de Datos** | Pandas | - | Manipulaci√≥n de datasets temporales |
| **An√°lisis de Datos** | NumPy | - | Operaciones num√©ricas y transformaciones |
| **Visualizaci√≥n** | Matplotlib | - | Gr√°ficos y an√°lisis exploratorio |
| **Visualizaci√≥n** | Seaborn | - | Visualizaciones estad√≠sticas |
| **Preprocessing** | LabelEncoder | - | Codificaci√≥n de variables categ√≥ricas |
| **M√©tricas** | RMSE | - | Evaluaci√≥n de regresi√≥n |
| **Utilidades** | Tabulate | - | Formateo de resultados |

## üìÑ Pipeline de Desarrollo

### 1. **Carga y Exploraci√≥n de Datos**
```python
# Carga de m√∫ltiples datasets relacionados
train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')
transactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv')
stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')
oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')
holidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')
test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')
```

**Datasets principales:**
- **train.csv:** Datos hist√≥ricos de ventas por tienda y familia de productos
- **test.csv:** Conjunto de evaluaci√≥n para predicciones futuras
- **stores.csv:** Informaci√≥n de tiendas (ubicaci√≥n, tipo, cluster)
- **transactions.csv:** N√∫mero de transacciones por tienda y fecha
- **oil.csv:** Precios diarios del petr√≥leo (factor econ√≥mico)
- **holidays_events.csv:** D√≠as festivos y eventos especiales

### 2. **Preprocesamiento y Ingenier√≠a de Caracter√≠sticas**

#### Conversi√≥n de Fechas y Extracci√≥n de Caracter√≠sticas Temporales
```python
# Conversi√≥n a formato datetime
for df in [train, test, transactions, oil, holidays]:
    df['date'] = pd.to_datetime(df['date'])

# Extracci√≥n de caracter√≠sticas temporales
for df in [train, test]:
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    df['weekday'] = df['date'].dt.weekday
```

**Beneficios de la ingenier√≠a temporal:**
- **Captura de patrones estacionales:** Variaciones mensuales y semanales
- **Tendencias anuales:** Cambios de comportamiento a√±o tras a√±o
- **Efectos de d√≠a de semana:** Patrones de compra por d√≠a
- **Compatibilidad con modelos:** Conversi√≥n de fechas a features num√©ricas

#### Fusi√≥n de Datos Multifuente
```python
# Merge complejo con m√∫ltiples datasets
train_merged = train.merge(stores, on='store_nbr', how='left') \
                    .merge(transactions, on=['date', 'store_nbr'], how='left') \
                    .merge(oil, on='date', how='left') \
                    .merge(holidays, left_on=['year', 'month', 'day'],
                           right_on=[holidays['date'].dt.year, holidays['date'].dt.month, holidays['date'].dt.day],
                           how='left', suffixes=('', '_holiday'))
```

**Estrategia de fusi√≥n:**
- **Left joins:** Preservaci√≥n de todas las observaciones de ventas
- **M√∫ltiples claves:** Combinaci√≥n por tienda, fecha y caracter√≠sticas temporales
- **Gesti√≥n de sufijos:** Manejo de columnas duplicadas
- **Contexto enriquecido:** Incorporaci√≥n de factores externos

### 3. **Limpieza y Transformaci√≥n de Datos**

#### Eliminaci√≥n de Caracter√≠sticas Irrelevantes
```python
# Columnas con alta cardinalidad o informaci√≥n redundante
columns_to_drop = ["transferred", "description", "locale_name", "locale", 
                   "type_holiday", "transactions", "date", "date_holiday"]
train_merged.drop(columns=columns_to_drop, inplace=True, errors='ignore')
test_merged.drop(columns=columns_to_drop, inplace=True, errors='ignore')
```

#### Imputaci√≥n y Manejo de Valores Faltantes
```python
# Imputaci√≥n por media para precios del petr√≥leo
train_merged['dcoilwtico'] = train_merged['dcoilwtico'].fillna(train_merged['dcoilwtico'].mean())
test_merged['dcoilwtico'] = test_merged['dcoilwtico'].fillna(test_merged['dcoilwtico'].mean())
```

**Justificaci√≥n de la estrategia:**
- **Media para variables continuas:** Preservaci√≥n de la distribuci√≥n central
- **Robustez:** Manejo de missing values sin p√©rdida de observaciones
- **Consistencia:** Aplicaci√≥n uniforme en train y test

### 4. **Codificaci√≥n de Variables Categ√≥ricas**

#### Label Encoding Sistem√°tico
```python
# Codificaci√≥n de todas las variables categ√≥ricas
categorical_cols = data_copy.select_dtypes(include=['object']).columns
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    data_copy[col] = le.fit_transform(data_copy[col].astype(str))
    test_copy[col] = le.transform(test_copy[col].astype(str))
    label_encoders[col] = le
```

**Ventajas del enfoque:**
- **Consistencia entre train/test:** Mismo mapping de categor√≠as
- **Preservaci√≥n de encoders:** Reutilizaci√≥n para nuevos datos
- **Manejo robusto:** Conversi√≥n a string para valores mixtos
- **Compatibilidad:** Preparaci√≥n para algoritmos tree-based

#### Alineaci√≥n de Datasets
```python
# Sincronizaci√≥n de columnas entre train y test
data_copy, test_copy = data_copy.align(test_copy, join='left', axis=1, fill_value=0)
```

### 5. **Transformaci√≥n de la Variable Objetivo**

#### Transformaci√≥n Logar√≠tmica
```python
# Log-transform para manejar distribuci√≥n sesgada de ventas
y_log = np.log1p(y)  # np.log1p evita problemas con ventas = 0
```

**Justificaci√≥n t√©cnica:**
- **Normalizaci√≥n de distribuci√≥n:** Reduce skewness de ventas
- **Estabilizaci√≥n de varianza:** Mejora homoscedasticidad
- **Manejo de ceros:** log1p(x) = log(1+x) evita log(0)
- **Mejora de performance:** Algoritmos funcionan mejor con datos normalizados

### 6. **Divisi√≥n de Datos y Configuraci√≥n del Modelo**

#### Split Estratificado
```python
# Divisi√≥n temporal para validaci√≥n
X_train, X_val, y_train_log, y_val_log = train_test_split(
    X, y_log, test_size=0.2, random_state=42
)
```

#### Configuraci√≥n Optimizada de CatBoost
```python
catboost_model = CatBoostRegressor(
    iterations=100000,          # Capacidad de aprendizaje extendida
    depth=9,                    # Profundidad para capturar interacciones complejas
    learning_rate=0.05,         # Learning rate conservador para estabilidad
    loss_function='RMSE',       # Funci√≥n de p√©rdida para regresi√≥n
    early_stopping_rounds=100,  # Prevenci√≥n de overfitting
    verbose=1000                # Monitoreo de progreso
)
```

**Hiperpar√°metros justificados:**
- **iterations=100000:** Capacidad suficiente para convergencia
- **depth=9:** Balance entre complejidad y generalizaci√≥n
- **learning_rate=0.05:** Velocidad moderada para estabilidad
- **early_stopping=100:** Prevenci√≥n robusta de overfitting

### 7. **Entrenamiento y Evaluaci√≥n**

#### Entrenamiento con Validaci√≥n
```python
# Entrenamiento con conjunto de validaci√≥n para early stopping
catboost_model.fit(X_train, y_train_log, eval_set=(X_val, y_val_log))
```

#### Evaluaci√≥n con Transformaci√≥n Inversa
```python
# Predicciones en escala logar√≠tmica
y_pred_log = catboost_model.predict(X_val)

# Inversi√≥n de transformaci√≥n logar√≠tmica
y_pred = np.expm1(y_pred_log)
y_val = np.expm1(y_val_log)

# C√°lculo de RMSE en escala original
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
print(f"RMSE del modelo CatBoost: {rmse}")
```

**Importancia de la evaluaci√≥n en escala original:**
- **Interpretabilidad:** RMSE en unidades de ventas reales
- **Validaci√≥n de transformaci√≥n:** Verificaci√≥n de inversi√≥n correcta
- **Comparabilidad:** M√©trica est√°ndar para competiciones

### 8. **Generaci√≥n de Predicciones Finales**

#### Predicci√≥n en Conjunto de Test
```python
# Predicciones finales con inversi√≥n de transformaci√≥n
y_test_pred_log = catboost_model.predict(test_copy)
y_test_pred = np.expm1(y_test_pred_log)

# Preparaci√≥n de submission
submission = pd.DataFrame({
    'id': test['id'],
    'sales': y_test_pred
})

submission.to_csv('submission.csv', index=False)
```

## üèóÔ∏è Estructura del Proyecto (Kaggle Environment)

### Entorno de Kaggle - Archivos y Datasets Disponibles:

```
COMPETITIONS:
‚îî‚îÄ‚îÄ store-sales-time-series-forecasting/
    ‚îú‚îÄ‚îÄ train.csv                              # Datos hist√≥ricos de ventas
    ‚îú‚îÄ‚îÄ test.csv                              # Conjunto de evaluaci√≥n
    ‚îú‚îÄ‚îÄ transactions.csv                      # Transacciones por tienda/fecha
    ‚îú‚îÄ‚îÄ stores.csv                            # Informaci√≥n de tiendas
    ‚îú‚îÄ‚îÄ oil.csv                               # Precios del petr√≥leo
    ‚îú‚îÄ‚îÄ holidays_events.csv                   # D√≠as festivos y eventos
    ‚îî‚îÄ‚îÄ sample_submission.csv                 # Formato de env√≠o

NOTEBOOK:
‚îî‚îÄ‚îÄ store_sales_catboost_forecasting.ipynb   # Notebook principal del proyecto

OUTPUT (/kaggle/working/):
‚îú‚îÄ‚îÄ catboost_info/                           # Logs y m√©tricas de CatBoost
‚îÇ   ‚îú‚îÄ‚îÄ learn/                              # M√©tricas de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ test/                               # M√©tricas de validaci√≥n
‚îî‚îÄ‚îÄ submission.csv                          # Archivo de env√≠o final
```

### Rutas de Acceso en C√≥digo:
```python
# Datos de entrada desde competitions
TRAIN_PATH = "/kaggle/input/store-sales-time-series-forecasting/train.csv"
TEST_PATH = "/kaggle/input/store-sales-time-series-forecasting/test.csv"
TRANSACTIONS_PATH = "/kaggle/input/store-sales-time-series-forecasting/transactions.csv"
STORES_PATH = "/kaggle/input/store-sales-time-series-forecasting/stores.csv"
OIL_PATH = "/kaggle/input/store-sales-time-series-forecasting/oil.csv"
HOLIDAYS_PATH = "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv"

# Outputs en working directory
SUBMISSION_PATH = "/kaggle/working/submission.csv"
CATBOOST_INFO_PATH = "/kaggle/working/catboost_info/"
```

## üöÄ C√≥mo Ejecutar el Proyecto en Kaggle

### Configuraci√≥n del Entorno Kaggle
```python
# Librer√≠as principales disponibles en Kaggle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
from catboost import CatBoostRegressor
import seaborn as sns
import matplotlib.pyplot as plt
```

### Verificaci√≥n de Datasets
```python
# Verificar disponibilidad de todos los datasets
import os

print("=== COMPETITION DATA ===")
for file in os.listdir('/kaggle/input/store-sales-time-series-forecasting/'):
    print(f"üìä {file}")
    
# Verificar tama√±os de datasets
datasets = ['train.csv', 'test.csv', 'transactions.csv', 'stores.csv', 'oil.csv', 'holidays_events.csv']
for dataset in datasets:
    df = pd.read_csv(f'/kaggle/input/store-sales-time-series-forecasting/{dataset}')
    print(f"{dataset}: {df.shape[0]} filas, {df.shape[1]} columnas")
```

### Ejecuci√≥n Paso a Paso

#### Paso 1: Crear y configurar notebook
1. **Crear notebook** en competici√≥n "Store Sales - Time Series Forecasting"
2. **Configurar acelerador**: Settings ‚Üí Accelerator ‚Üí GPU P100 (opcional para CatBoost)
3. **Agregar datasets**:
   - **Competition Data**: Store Sales - Time Series Forecasting

#### Paso 2: An√°lisis exploratorio inicial
```python
# Exploraci√≥n b√°sica de los datos principales
train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')
print("=== INFORMACI√ìN DEL DATASET DE ENTRENAMIENTO ===")
print(f"Forma del dataset: {train.shape}")
print(f"Rango de fechas: {train['date'].min()} a {train['date'].max()}")
print(f"N√∫mero de tiendas: {train['store_nbr'].nunique()}")
print(f"N√∫mero de familias de productos: {train['family'].nunique()}")
print(f"Estad√≠sticas de ventas:")
print(train['sales'].describe())
```

### Flujo de Ejecuci√≥n en Kaggle

#### 1. **Carga y Preprocessamiento**
```python
# Carga completa de datasets
datasets = {}
file_names = ['train', 'test', 'transactions', 'stores', 'oil', 'holidays_events']
for name in file_names:
    datasets[name] = pd.read_csv(f'/kaggle/input/store-sales-time-series-forecasting/{name}.csv')
    
# Conversi√≥n de fechas
for df_name in ['train', 'test', 'transactions', 'oil', 'holidays_events']:
    datasets[df_name]['date'] = pd.to_datetime(datasets[df_name]['date'])
```

#### 2. **Ingenier√≠a de Caracter√≠sticas**
```python
# Extracci√≥n de caracter√≠sticas temporales
for df_name in ['train', 'test']:
    df = datasets[df_name]
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    df['weekday'] = df['date'].dt.weekday
    df['quarter'] = df['date'].dt.quarter
    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
```

#### 3. **Fusi√≥n de Datos**
```python
# Merge sistem√°tico de todas las fuentes
def merge_all_data(main_df, datasets):
    merged = main_df.copy()
    
    # Merge con stores
    merged = merged.merge(datasets['stores'], on='store_nbr', how='left')
    
    # Merge con transactions
    merged = merged.merge(datasets['transactions'], on=['date', 'store_nbr'], how='left')
    
    # Merge con oil
    merged = merged.merge(datasets['oil'], on='date', how='left')
    
    # Merge con holidays (m√°s complejo por fechas)
    holidays_df = datasets['holidays_events'].copy()
    holidays_df['year'] = holidays_df['date'].dt.year
    holidays_df['month'] = holidays_df['date'].dt.month
    holidays_df['day'] = holidays_df['date'].dt.day
    
    merged = merged.merge(holidays_df[['year', 'month', 'day', 'type', 'locale']], 
                         on=['year', 'month', 'day'], how='left')
    
    return merged

train_merged = merge_all_data(datasets['train'], datasets)
test_merged = merge_all_data(datasets['test'], datasets)
```

#### 4. **Configuraci√≥n y Entrenamiento de CatBoost**
```python
# Preparaci√≥n de datos para CatBoost
X = train_processed.drop(['sales', 'id'], axis=1, errors='ignore')
y = train_processed['sales']

# Transformaci√≥n logar√≠tmica
y_log = np.log1p(y)

# Divisi√≥n train/validation
X_train, X_val, y_train_log, y_val_log = train_test_split(
    X, y_log, test_size=0.2, random_state=42, shuffle=True
)

# Configuraci√≥n optimizada de CatBoost
model = CatBoostRegressor(
    iterations=100000,
    depth=9,
    learning_rate=0.05,
    loss_function='RMSE',
    early_stopping_rounds=100,
    verbose=1000,
    random_state=42
)

# Entrenamiento con validaci√≥n
model.fit(X_train, y_train_log, eval_set=(X_val, y_val_log))
```

#### 5. **Evaluaci√≥n y Predicci√≥n Final**
```python
# Evaluaci√≥n en conjunto de validaci√≥n
y_pred_log = model.predict(X_val)
y_pred = np.expm1(y_pred_log)
y_val_original = np.expm1(y_val_log)

rmse = np.sqrt(mean_squared_error(y_val_original, y_pred))
print(f"RMSE en conjunto de validaci√≥n: {rmse:.2f}")

# Predicciones finales
X_test = test_processed.drop(['id'], axis=1, errors='ignore')
test_pred_log = model.predict(X_test)
test_pred = np.expm1(test_pred_log)

# Crear submission
submission = pd.DataFrame({
    'id': datasets['test']['id'],
    'sales': test_pred
})

submission.to_csv('/kaggle/working/submission.csv', index=False)
print("‚úÖ Archivo submission.csv creado exitosamente")
```

## üìà Resultados y M√©tricas

### Modelo Principal: CatBoost Optimizado
**Configuraci√≥n final:**
- **Arquitectmo:** Gradient Boosting on Decision Trees
- **Iteraciones:** 100,000 (con early stopping)
- **Profundidad:** 9 niveles de √°rboles
- **Learning Rate:** 0.05 (conservador para estabilidad)
- **Loss Function:** RMSE (optimizada para regresi√≥n)
- **Early Stopping:** 100 rondas sin mejora

### M√©tricas de Evaluaci√≥n
- **M√©trica principal:** RMSE (Root Mean Squared Error)
- **Transformaci√≥n:** Evaluaci√≥n en escala original de ventas
- **Validaci√≥n:** Hold-out 20% con early stopping
- **Robustez:** Manejo de datos faltantes autom√°tico

### T√©cnicas de Optimizaci√≥n Implementadas
1. **Transformaci√≥n logar√≠tmica:** Normalizaci√≥n de distribuci√≥n de ventas
2. **Ingenier√≠a temporal:** Extracci√≥n de patrones estacionales
3. **Fusi√≥n multifuente:** Incorporaci√≥n de factores externos
4. **Early stopping:** Prevenci√≥n autom√°tica de overfitting
5. **Imputaci√≥n inteligente:** Manejo robusto de valores faltantes

## üî¨ Innovaciones T√©cnicas

### Fortalezas del Enfoque Time Series
1. **Fusi√≥n de datos heterog√©neos:** Combinaci√≥n de ventas, transacciones, econom√≠a y calendario
2. **Transformaci√≥n estabilizadora:** Log-transform para manejo de outliers
3. **Caracter√≠sticas temporales:** Captura de patrones c√≠clicos y estacionales
4. **Modelo robusto:** CatBoost maneja autom√°ticamente variables categ√≥ricas

### Aspectos √önicos del Proyecto
- **Enfoque multifactor:** Integraci√≥n de factores econ√≥micos (petr√≥leo) y sociales (festivos)
- **Preprocessing autom√°tico:** Pipeline robusto para datos del mundo real
- **Escalabilidad:** Manejo eficiente de datasets grandes con CatBoost
- **Robustez temporal:** Consideraci√≥n de efectos de calendario y estacionalidad

## üéØ Posibles Mejoras

### T√©cnicas Avanzadas de Machine Learning
1. **Ensemble de modelos:** Combinaci√≥n con XGBoost, LightGBM y Random Forest
2. **Stacking avanzado:** Uso de meta-learners para combinaci√≥n √≥ptima
3. **Feature engineering autom√°tico:** Creaci√≥n de interacciones y polinomios
4. **Optimizaci√≥n de hiperpar√°metros:** Bayesian optimization o grid search

### Ingenier√≠a de Caracter√≠sticas Temporales Avanzadas
1. **Lags y windows:** Caracter√≠sticas de ventas pasadas y promedios m√≥viles
2. **Caracter√≠sticas de tendencia:** Crecimiento, aceleraci√≥n y cambios de r√©gimen
3. **Estacionalidad compleja:** Descomposici√≥n STL y Fourier features
4. **Eventos especiales:** Modelado espec√≠fico de Black Friday, Navidad, etc.

### T√©cnicas de Series Temporales Especializadas
1. **Prophet:** Modelo de Facebook para series temporales con estacionalidad
2. **ARIMA/SARIMA:** Modelos cl√°sicos para componentes autorregresivos
3. **Deep Learning:** LSTM/GRU para patrones temporales complejos
4. **Hybrid models:** Combinaci√≥n de enfoques estad√≠sticos y ML

### Optimizaci√≥n Avanzada
1. **Cross-validation temporal:** Validaci√≥n espec√≠fica para series temporales
2. **Custom loss functions:** P√©rdidas asim√©tricas para retail
3. **Online learning:** Actualizaci√≥n incremental con nuevos datos
4. **Multi-target:** Predicci√≥n simult√°nea de m√∫ltiples horizontes

## üéØ Aplicaciones del Mundo Real

### Impacto en Retail y Supply Chain
- **Planificaci√≥n de inventario:** Optimizaci√≥n de stock por tienda
- **Gesti√≥n de cadena de suministro:** Predicci√≥n de demanda para log√≠stica
- **Pricing estrat√©gico:** Ajuste de precios basado en demanda predicha
- **Staffing optimization:** Planificaci√≥n de personal por ventas esperadas

### Escalabilidad y Transferencia
1. **Otros sectores retail:** Aplicaci√≥n a supermercados, farmacias, e-commerce
2. **Diferentes geograf√≠as:** Adaptaci√≥n a mercados con distintas caracter√≠sticas
3. **M√∫ltiples horizontes:** Predicci√≥n semanal, mensual y trimestral
4. **Real-time deployment:** Sistemas de predicci√≥n en tiempo real

## üîß Consideraciones T√©cnicas

### Consideraciones Espec√≠ficas de Kaggle

#### Limitaciones del Entorno
- **Tiempo de ejecuci√≥n:** M√°ximo 12 horas por sesi√≥n
- **Memoria RAM:** 16GB disponibles para datasets grandes
- **CPU:** Procesamiento paralelo para CatBoost
- **Almacenamiento:** 20GB en /working para checkpoints

#### Optimizaciones para Kaggle
```python
# Configuraci√≥n de memoria eficiente para CatBoost
import gc

# Liberaci√≥n de memoria despu√©s de preprocessing
del train_raw, test_raw
gc.collect()

# Configuraci√≥n de CatBoost para Kaggle
catboost_params = {
    'iterations': 100000,
    'depth': 9,
    'learning_rate': 0.05,
    'thread_count': -1,  # Usar todos los cores disponibles
    'verbose': 1000,
    'allow_writing_files': False  # No escribir archivos temporales
}
```

#### Gesti√≥n Eficiente de Datos
```python
# Verificar uso de memoria
def check_memory_usage():
    import psutil
    memory = psutil.virtual_memory()
    print(f"Memoria total: {memory.total / (1024**3):.1f} GB")
    print(f"Memoria disponible: {memory.available / (1024**3):.1f} GB")
    print(f"Memoria usada: {memory.percent:.1f}%")

# Optimizaci√≥n de tipos de datos
def optimize_dtypes(df):
    for col in df.select_dtypes(include=['int64']).columns:
        if df[col].min() >= 0:
            if df[col].max() < 255:
                df[col] = df[col].astype('uint8')
            elif df[col].max() < 65535:
                df[col] = df[col].astype('uint16')
            else:
                df[col] = df[col].astype('uint32')
    
    for col in df.select_dtypes(include=['float64']).columns:
        df[col] = pd.to_numeric(df[col], downcast='float')
    
    return df
```

### Reproducibilidad y Debugging
```python
# Configuraci√≥n de semillas para reproducibilidad
import random
import os

def set_random_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

# Logging detallado para debugging
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def log_data_info(df, name):
    logger.info(f"Dataset {name}: {df.shape[0]} filas, {df.shape[1]} columnas")
    logger.info(f"Memoria usada: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    logger.info(f"Valores nulos: {df.isnull().sum().sum()}")
```

## üìû Contacto y Colaboraci√≥n

Para consultas t√©cnicas, colaboraciones en proyectos de forecasting, o discusiones sobre aplicaciones de machine learning en retail y supply chain, no dudes en contactar.

## üìó Referencias y Recursos

- **CatBoost Documentation:** Gu√≠a oficial y best practices
- **Time Series Forecasting:** Literatura sobre predicci√≥n en retail
- **Feature Engineering:** T√©cnicas avanzadas para series temporales
- **Kaggle Competitions:** An√°lisis de soluciones ganadoras en forecasting

---

*Este proyecto representa una aplicaci√≥n integral de machine learning para forecasting en retail, combinando m√∫ltiples fuentes de datos, ingenier√≠a de caracter√≠sticas avanzada y el poder de CatBoost para crear predicciones precisas de ventas que pueden impulsar decisiones estrat√©gicas en el mundo real.*