# PredicciÃ³n de Ventas de Tiendas con CatBoost - Machine Learning Time Series Project

Este proyecto implementa una soluciÃ³n completa para la competiciÃ³n de Kaggle "Store Sales - Time Series Forecasting" utilizando tÃ©cnicas avanzadas de machine learning y el algoritmo CatBoost. El objetivo es predecir las ventas de productos en diferentes tiendas utilizando datos histÃ³ricos, informaciÃ³n de transacciones, precios del petrÃ³leo, dÃ­as festivos y caracterÃ­sticas de las tiendas.

## ðŸ§  DescripciÃ³n del Proyecto

El proyecto utiliza **CatBoost Regressor** como modelo principal para realizar predicciones de series temporales en un contexto de retail. A travÃ©s de ingenierÃ­a de caracterÃ­sticas temporales, fusiÃ³n de mÃºltiples fuentes de datos y transformaciones logarÃ­tmicas, se construye un predictor robusto capaz de estimar las ventas futuras con alta precisiÃ³n.

## ðŸ“Š TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|-----------|------------|---------|-----------|
| **Lenguaje** | Python | 3.x | Lenguaje principal de desarrollo |
| **Machine Learning** | CatBoost | - | Algoritmo principal de regresiÃ³n |
| **ML Complementario** | XGBoost | - | Modelo de ensemble (preparado) |
| **ML Tradicional** | Scikit-learn | - | Ridge regression y mÃ©tricas |
| **AnÃ¡lisis de Datos** | Pandas | - | ManipulaciÃ³n de datasets temporales |
| **AnÃ¡lisis de Datos** | NumPy | - | Operaciones numÃ©ricas y transformaciones |
| **VisualizaciÃ³n** | Matplotlib | - | GrÃ¡ficos y anÃ¡lisis exploratorio |
| **VisualizaciÃ³n** | Seaborn | - | Visualizaciones estadÃ­sticas |
| **Preprocessing** | LabelEncoder | - | CodificaciÃ³n de variables categÃ³ricas |
| **MÃ©tricas** | RMSE | - | EvaluaciÃ³n de regresiÃ³n |
| **Utilidades** | Tabulate | - | Formateo de resultados |

## ðŸ“„ Pipeline de Desarrollo

### 1. **Carga y ExploraciÃ³n de Datos**
```python
# Carga de mÃºltiples datasets relacionados
train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')
transactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv')
stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')
oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')
holidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')
test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')
```

**Datasets principales:**
- **train.csv:** Datos histÃ³ricos de ventas por tienda y familia de productos
- **test.csv:** Conjunto de evaluaciÃ³n para predicciones futuras
- **stores.csv:** InformaciÃ³n de tiendas (ubicaciÃ³n, tipo, cluster)
- **transactions.csv:** NÃºmero de transacciones por tienda y fecha
- **oil.csv:** Precios diarios del petrÃ³leo (factor econÃ³mico)
- **holidays_events.csv:** DÃ­as festivos y eventos especiales

### 2. **Preprocesamiento y IngenierÃ­a de CaracterÃ­sticas**

#### ConversiÃ³n de Fechas y ExtracciÃ³n de CaracterÃ­sticas Temporales
```python
# ConversiÃ³n a formato datetime
for df in [train, test, transactions, oil, holidays]:
    df['date'] = pd.to_datetime(df['date'])

# ExtracciÃ³n de caracterÃ­sticas temporales
for df in [train, test]:
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    df['weekday'] = df['date'].dt.weekday
```

**Beneficios de la ingenierÃ­a temporal:**
- **Captura de patrones estacionales:** Variaciones mensuales y semanales
- **Tendencias anuales:** Cambios de comportamiento aÃ±o tras aÃ±o
- **Efectos de dÃ­a de semana:** Patrones de compra por dÃ­a
- **Compatibilidad con modelos:** ConversiÃ³n de fechas a features numÃ©ricas

#### FusiÃ³n de Datos Multifuente
```python
# Merge complejo con mÃºltiples datasets
train_merged = train.merge(stores, on='store_nbr', how='left') \
                    .merge(transactions, on=['date', 'store_nbr'], how='left') \
                    .merge(oil, on='date', how='left') \
                    .merge(holidays, left_on=['year', 'month', 'day'],
                           right_on=[holidays['date'].dt.year, holidays['date'].dt.month, holidays['date'].dt.day],
                           how='left', suffixes=('', '_holiday'))
```

**Estrategia de fusiÃ³n:**
- **Left joins:** PreservaciÃ³n de todas las observaciones de ventas
- **MÃºltiples claves:** CombinaciÃ³n por tienda, fecha y caracterÃ­sticas temporales
- **GestiÃ³n de sufijos:** Manejo de columnas duplicadas
- **Contexto enriquecido:** IncorporaciÃ³n de factores externos

### 3. **Limpieza y TransformaciÃ³n de Datos**

#### EliminaciÃ³n de CaracterÃ­sticas Irrelevantes
```python
# Columnas con alta cardinalidad o informaciÃ³n redundante
columns_to_drop = ["transferred", "description", "locale_name", "locale", 
                   "type_holiday", "transactions", "date", "date_holiday"]
train_merged.drop(columns=columns_to_drop, inplace=True, errors='ignore')
test_merged.drop(columns=columns_to_drop, inplace=True, errors='ignore')
```

#### ImputaciÃ³n y Manejo de Valores Faltantes
```python
# ImputaciÃ³n por media para precios del petrÃ³leo
train_merged['dcoilwtico'] = train_merged['dcoilwtico'].fillna(train_merged['dcoilwtico'].mean())
test_merged['dcoilwtico'] = test_merged['dcoilwtico'].fillna(test_merged['dcoilwtico'].mean())
```

**JustificaciÃ³n de la estrategia:**
- **Media para variables continuas:** PreservaciÃ³n de la distribuciÃ³n central
- **Robustez:** Manejo de missing values sin pÃ©rdida de observaciones
- **Consistencia:** AplicaciÃ³n uniforme en train y test

### 4. **CodificaciÃ³n de Variables CategÃ³ricas**

#### Label Encoding SistemÃ¡tico
```python
# CodificaciÃ³n de todas las variables categÃ³ricas
categorical_cols = data_copy.select_dtypes(include=['object']).columns
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    data_copy[col] = le.fit_transform(data_copy[col].astype(str))
    test_copy[col] = le.transform(test_copy[col].astype(str))
    label_encoders[col] = le
```

**Ventajas del enfoque:**
- **Consistencia entre train/test:** Mismo mapping de categorÃ­as
- **PreservaciÃ³n de encoders:** ReutilizaciÃ³n para nuevos datos
- **Manejo robusto:** ConversiÃ³n a string para valores mixtos
- **Compatibilidad:** PreparaciÃ³n para algoritmos tree-based

#### AlineaciÃ³n de Datasets
```python
# SincronizaciÃ³n de columnas entre train y test
data_copy, test_copy = data_copy.align(test_copy, join='left', axis=1, fill_value=0)
```

### 5. **TransformaciÃ³n de la Variable Objetivo**

#### TransformaciÃ³n LogarÃ­tmica
```python
# Log-transform para manejar distribuciÃ³n sesgada de ventas
y_log = np.log1p(y)  # np.log1p evita problemas con ventas = 0
```

**JustificaciÃ³n tÃ©cnica:**
- **NormalizaciÃ³n de distribuciÃ³n:** Reduce skewness de ventas
- **EstabilizaciÃ³n de varianza:** Mejora homoscedasticidad
- **Manejo de ceros:** log1p(x) = log(1+x) evita log(0)
- **Mejora de performance:** Algoritmos funcionan mejor con datos normalizados

### 6. **DivisiÃ³n de Datos y ConfiguraciÃ³n del Modelo**

#### Split Estratificado
```python
# DivisiÃ³n temporal para validaciÃ³n
X_train, X_val, y_train_log, y_val_log = train_test_split(
    X, y_log, test_size=0.2, random_state=42
)
```

#### ConfiguraciÃ³n Optimizada de CatBoost
```python
catboost_model = CatBoostRegressor(
    iterations=100000,          # Capacidad de aprendizaje extendida
    depth=9,                    # Profundidad para capturar interacciones complejas
    learning_rate=0.05,         # Learning rate conservador para estabilidad
    loss_function='RMSE',       # FunciÃ³n de pÃ©rdida para regresiÃ³n
    early_stopping_rounds=100,  # PrevenciÃ³n de overfitting
    verbose=1000                # Monitoreo de progreso
)
```

**HiperparÃ¡metros justificados:**
- **iterations=100000:** Capacidad suficiente para convergencia
- **depth=9:** Balance entre complejidad y generalizaciÃ³n
- **learning_rate=0.05:** Velocidad moderada para estabilidad
- **early_stopping=100:** PrevenciÃ³n robusta de overfitting

### 7. **Entrenamiento y EvaluaciÃ³n**

#### Entrenamiento con ValidaciÃ³n
```python
# Entrenamiento con conjunto de validaciÃ³n para early stopping
catboost_model.fit(X_train, y_train_log, eval_set=(X_val, y_val_log))
```

#### EvaluaciÃ³n con TransformaciÃ³n Inversa
```python
# Predicciones en escala logarÃ­tmica
y_pred_log = catboost_model.predict(X_val)

# InversiÃ³n de transformaciÃ³n logarÃ­tmica
y_pred = np.expm1(y_pred_log)
y_val = np.expm1(y_val_log)

# CÃ¡lculo de RMSE en escala original
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
print(f"RMSE del modelo CatBoost: {rmse}")
```

**Importancia de la evaluaciÃ³n en escala original:**
- **Interpretabilidad:** RMSE en unidades de ventas reales
- **ValidaciÃ³n de transformaciÃ³n:** VerificaciÃ³n de inversiÃ³n correcta
- **Comparabilidad:** MÃ©trica estÃ¡ndar para competiciones

### 8. **GeneraciÃ³n de Predicciones Finales**

#### PredicciÃ³n en Conjunto de Test
```python
# Predicciones finales con inversiÃ³n de transformaciÃ³n
y_test_pred_log = catboost_model.predict(test_copy)
y_test_pred = np.expm1(y_test_pred_log)

# PreparaciÃ³n de submission
submission = pd.DataFrame({
    'id': test['id'],
    'sales': y_test_pred
})

submission.to_csv('submission.csv', index=False)
```

## ðŸ—ï¸ Estructura del Proyecto (Kaggle Environment)

### Entorno de Kaggle - Archivos y Datasets Disponibles:

```
COMPETITIONS:
â””â”€â”€ store-sales-time-series-forecasting/
    â”œâ”€â”€ train.csv                              # Datos histÃ³ricos de ventas
    â”œâ”€â”€ test.csv                              # Conjunto de evaluaciÃ³n
    â”œâ”€â”€ transactions.csv                      # Transacciones por tienda/fecha
    â”œâ”€â”€ stores.csv                            # InformaciÃ³n de tiendas
    â”œâ”€â”€ oil.csv                               # Precios del petrÃ³leo
    â”œâ”€â”€ holidays_events.csv                   # DÃ­as festivos y eventos
    â””â”€â”€ sample_submission.csv                 # Formato de envÃ­o

NOTEBOOK:
â””â”€â”€ store_sales_catboost_forecasting.ipynb   # Notebook principal del proyecto

OUTPUT (/kaggle/working/):
â”œâ”€â”€ catboost_info/                           # Logs y mÃ©tricas de CatBoost
â”‚   â”œâ”€â”€ learn/                              # MÃ©tricas de entrenamiento
â”‚   â””â”€â”€ test/                               # MÃ©tricas de validaciÃ³n
â””â”€â”€ submission.csv                          # Archivo de envÃ­o final
```

### Rutas de Acceso en CÃ³digo:
```python
# Datos de entrada desde competitions
TRAIN_PATH = "/kaggle/input/store-sales-time-series-forecasting/train.csv"
TEST_PATH = "/kaggle/input/store-sales-time-series-forecasting/test.csv"
TRANSACTIONS_PATH = "/kaggle/input/store-sales-time-series-forecasting/transactions.csv"
STORES_PATH = "/kaggle/input/store-sales-time-series-forecasting/stores.csv"
OIL_PATH = "/kaggle/input/store-sales-time-series-forecasting/oil.csv"
HOLIDAYS_PATH = "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv"

# Outputs en working directory
SUBMISSION_PATH = "/kaggle/working/submission.csv"
CATBOOST_INFO_PATH = "/kaggle/working/catboost_info/"
```

## ðŸš€ CÃ³mo Ejecutar el Proyecto en Kaggle

### ConfiguraciÃ³n del Entorno Kaggle
```python
# LibrerÃ­as principales disponibles en Kaggle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
from catboost import CatBoostRegressor
import seaborn as sns
import matplotlib.pyplot as plt
```

### VerificaciÃ³n de Datasets
```python
# Verificar disponibilidad de todos los datasets
import os

print("=== COMPETITION DATA ===")
for file in os.listdir('/kaggle/input/store-sales-time-series-forecasting/'):
    print(f"ðŸ“Š {file}")
    
# Verificar tamaÃ±os de datasets
datasets = ['train.csv', 'test.csv', 'transactions.csv', 'stores.csv', 'oil.csv', 'holidays_events.csv']
for dataset in datasets:
    df = pd.read_csv(f'/kaggle/input/store-sales-time-series-forecasting/{dataset}')
    print(f"{dataset}: {df.shape[0]} filas, {df.shape[1]} columnas")
```

### EjecuciÃ³n Paso a Paso

#### Paso 1: Crear y configurar notebook
1. **Crear notebook** en competiciÃ³n "Store Sales - Time Series Forecasting"
2. **Configurar acelerador**: Settings â†’ Accelerator â†’ GPU P100 (opcional para CatBoost)
3. **Agregar datasets**:
   - **Competition Data**: Store Sales - Time Series Forecasting

#### Paso 2: AnÃ¡lisis exploratorio inicial
```python
# ExploraciÃ³n bÃ¡sica de los datos principales
train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')
print("=== INFORMACIÃ“N DEL DATASET DE ENTRENAMIENTO ===")
print(f"Forma del dataset: {train.shape}")
print(f"Rango de fechas: {train['date'].min()} a {train['date'].max()}")
print(f"NÃºmero de tiendas: {train['store_nbr'].nunique()}")
print(f"NÃºmero de familias de productos: {train['family'].nunique()}")
print(f"EstadÃ­sticas de ventas:")
print(train['sales'].describe())
```

### Flujo de EjecuciÃ³n en Kaggle

#### 1. **Carga y Preprocessamiento**
```python
# Carga completa de datasets
datasets = {}
file_names = ['train', 'test', 'transactions', 'stores', 'oil', 'holidays_events']
for name in file_names:
    datasets[name] = pd.read_csv(f'/kaggle/input/store-sales-time-series-forecasting/{name}.csv')
    
# ConversiÃ³n de fechas
for df_name in ['train', 'test', 'transactions', 'oil', 'holidays_events']:
    datasets[df_name]['date'] = pd.to_datetime(datasets[df_name]['date'])
```

#### 2. **IngenierÃ­a de CaracterÃ­sticas**
```python
# ExtracciÃ³n de caracterÃ­sticas temporales
for df_name in ['train', 'test']:
    df = datasets[df_name]
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    df['weekday'] = df['date'].dt.weekday
    df['quarter'] = df['date'].dt.quarter
    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
```

#### 3. **FusiÃ³n de Datos**
```python
# Merge sistemÃ¡tico de todas las fuentes
def merge_all_data(main_df, datasets):
    merged = main_df.copy()
    
    # Merge con stores
    merged = merged.merge(datasets['stores'], on='store_nbr', how='left')
    
    # Merge con transactions
    merged = merged.merge(datasets['transactions'], on=['date', 'store_nbr'], how='left')
    
    # Merge con oil
    merged = merged.merge(datasets['oil'], on='date', how='left')
    
    # Merge con holidays (mÃ¡s complejo por fechas)
    holidays_df = datasets['holidays_events'].copy()
    holidays_df['year'] = holidays_df['date'].dt.year
    holidays_df['month'] = holidays_df['date'].dt.month
    holidays_df['day'] = holidays_df['date'].dt.day
    
    merged = merged.merge(holidays_df[['year', 'month', 'day', 'type', 'locale']], 
                         on=['year', 'month', 'day'], how='left')
    
    return merged

train_merged = merge_all_data(datasets['train'], datasets)
test_merged = merge_all_data(datasets['test'], datasets)
```

#### 4. **ConfiguraciÃ³n y Entrenamiento de CatBoost**
```python
# PreparaciÃ³n de datos para CatBoost
X = train_processed.drop(['sales', 'id'], axis=1, errors='ignore')
y = train_processed['sales']

# TransformaciÃ³n logarÃ­tmica
y_log = np.log1p(y)

# DivisiÃ³n train/validation
X_train, X_val, y_train_log, y_val_log = train_test_split(
    X, y_log, test_size=0.2, random_state=42, shuffle=True
)

# ConfiguraciÃ³n optimizada de CatBoost
model = CatBoostRegressor(
    iterations=100000,
    depth=9,
    learning_rate=0.05,
    loss_function='RMSE',
    early_stopping_rounds=100,
    verbose=1000,
    random_state=42
)

# Entrenamiento con validaciÃ³n
model.fit(X_train, y_train_log, eval_set=(X_val, y_val_log))
```

#### 5. **EvaluaciÃ³n y PredicciÃ³n Final**
```python
# EvaluaciÃ³n en conjunto de validaciÃ³n
y_pred_log = model.predict(X_val)
y_pred = np.expm1(y_pred_log)
y_val_original = np.expm1(y_val_log)

rmse = np.sqrt(mean_squared_error(y_val_original, y_pred))
print(f"RMSE en conjunto de validaciÃ³n: {rmse:.2f}")

# Predicciones finales
X_test = test_processed.drop(['id'], axis=1, errors='ignore')
test_pred_log = model.predict(X_test)
test_pred = np.expm1(test_pred_log)

# Crear submission
submission = pd.DataFrame({
    'id': datasets['test']['id'],
    'sales': test_pred
})

submission.to_csv('/kaggle/working/submission.csv', index=False)
print("âœ… Archivo submission.csv creado exitosamente")
```

## ðŸ“ˆ Resultados y MÃ©tricas

### Modelo Principal: CatBoost Optimizado
**ConfiguraciÃ³n final:**
- **Arquitectmo:** Gradient Boosting on Decision Trees
- **Iteraciones:** 100,000 (con early stopping)
- **Profundidad:** 9 niveles de Ã¡rboles
- **Learning Rate:** 0.05 (conservador para estabilidad)
- **Loss Function:** RMSE (optimizada para regresiÃ³n)
- **Early Stopping:** 100 rondas sin mejora

### MÃ©tricas de EvaluaciÃ³n
- **MÃ©trica principal:** RMSE (Root Mean Squared Error)
- **TransformaciÃ³n:** EvaluaciÃ³n en escala original de ventas
- **ValidaciÃ³n:** Hold-out 20% con early stopping
- **Robustez:** Manejo de datos faltantes automÃ¡tico

### TÃ©cnicas de OptimizaciÃ³n Implementadas
1. **TransformaciÃ³n logarÃ­tmica:** NormalizaciÃ³n de distribuciÃ³n de ventas
2. **IngenierÃ­a temporal:** ExtracciÃ³n de patrones estacionales
3. **FusiÃ³n multifuente:** IncorporaciÃ³n de factores externos
4. **Early stopping:** PrevenciÃ³n automÃ¡tica de overfitting
5. **ImputaciÃ³n inteligente:** Manejo robusto de valores faltantes

## ðŸ”¬ Innovaciones TÃ©cnicas

### Fortalezas del Enfoque Time Series
1. **FusiÃ³n de datos heterogÃ©neos:** CombinaciÃ³n de ventas, transacciones, economÃ­a y calendario
2. **TransformaciÃ³n estabilizadora:** Log-transform para manejo de outliers
3. **CaracterÃ­sticas temporales:** Captura de patrones cÃ­clicos y estacionales
4. **Modelo robusto:** CatBoost maneja automÃ¡ticamente variables categÃ³ricas

### Aspectos Ãšnicos del Proyecto
- **Enfoque multifactor:** IntegraciÃ³n de factores econÃ³micos (petrÃ³leo) y sociales (festivos)
- **Preprocessing automÃ¡tico:** Pipeline robusto para datos del mundo real
- **Escalabilidad:** Manejo eficiente de datasets grandes con CatBoost
- **Robustez temporal:** ConsideraciÃ³n de efectos de calendario y estacionalidad

## ðŸŽ¯ Posibles Mejoras

### TÃ©cnicas Avanzadas de Machine Learning
1. **Ensemble de modelos:** CombinaciÃ³n con XGBoost, LightGBM y Random Forest
2. **Stacking avanzado:** Uso de meta-learners para combinaciÃ³n Ã³ptima
3. **Feature engineering automÃ¡tico:** CreaciÃ³n de interacciones y polinomios
4. **OptimizaciÃ³n de hiperparÃ¡metros:** Bayesian optimization o grid search

### IngenierÃ­a de CaracterÃ­sticas Temporales Avanzadas
1. **Lags y windows:** CaracterÃ­sticas de ventas pasadas y promedios mÃ³viles
2. **CaracterÃ­sticas de tendencia:** Crecimiento, aceleraciÃ³n y cambios de rÃ©gimen
3. **Estacionalidad compleja:** DescomposiciÃ³n STL y Fourier features
4. **Eventos especiales:** Modelado especÃ­fico de Black Friday, Navidad, etc.

### TÃ©cnicas de Series Temporales Especializadas
1. **Prophet:** Modelo de Facebook para series temporales con estacionalidad
2. **ARIMA/SARIMA:** Modelos clÃ¡sicos para componentes autorregresivos
3. **Deep Learning:** LSTM/GRU para patrones temporales complejos
4. **Hybrid models:** CombinaciÃ³n de enfoques estadÃ­sticos y ML

### OptimizaciÃ³n Avanzada
1. **Cross-validation temporal:** ValidaciÃ³n especÃ­fica para series temporales
2. **Custom loss functions:** PÃ©rdidas asimÃ©tricas para retail
3. **Online learning:** ActualizaciÃ³n incremental con nuevos datos
4. **Multi-target:** PredicciÃ³n simultÃ¡nea de mÃºltiples horizontes

## ðŸŽ¯ Aplicaciones del Mundo Real

### Impacto en Retail y Supply Chain
- **PlanificaciÃ³n de inventario:** OptimizaciÃ³n de stock por tienda
- **GestiÃ³n de cadena de suministro:** PredicciÃ³n de demanda para logÃ­stica
- **Pricing estratÃ©gico:** Ajuste de precios basado en demanda predicha
- **Staffing optimization:** PlanificaciÃ³n de personal por ventas esperadas

### Escalabilidad y Transferencia
1. **Otros sectores retail:** AplicaciÃ³n a supermercados, farmacias, e-commerce
2. **Diferentes geografÃ­as:** AdaptaciÃ³n a mercados con distintas caracterÃ­sticas
3. **MÃºltiples horizontes:** PredicciÃ³n semanal, mensual y trimestral
4. **Real-time deployment:** Sistemas de predicciÃ³n en tiempo real

## ðŸ”§ Consideraciones TÃ©cnicas

### Consideraciones EspecÃ­ficas de Kaggle

#### Limitaciones del Entorno
- **Tiempo de ejecuciÃ³n:** MÃ¡ximo 12 horas por sesiÃ³n
- **Memoria RAM:** 16GB disponibles para datasets grandes
- **CPU:** Procesamiento paralelo para CatBoost
- **Almacenamiento:** 20GB en /working para checkpoints

#### Optimizaciones para Kaggle
```python
# ConfiguraciÃ³n de memoria eficiente para CatBoost
import gc

# LiberaciÃ³n de memoria despuÃ©s de preprocessing
del train_raw, test_raw
gc.collect()

# ConfiguraciÃ³n de CatBoost para Kaggle
catboost_params = {
    'iterations': 100000,
    'depth': 9,
    'learning_rate': 0.05,
    'thread_count': -1,  # Usar todos los cores disponibles
    'verbose': 1000,
    'allow_writing_files': False  # No escribir archivos temporales
}
```

#### GestiÃ³n Eficiente de Datos
```python
# Verificar uso de memoria
def check_memory_usage():
    import psutil
    memory = psutil.virtual_memory()
    print(f"Memoria total: {memory.total / (1024**3):.1f} GB")
    print(f"Memoria disponible: {memory.available / (1024**3):.1f} GB")
    print(f"Memoria usada: {memory.percent:.1f}%")

# OptimizaciÃ³n de tipos de datos
def optimize_dtypes(df):
    for col in df.select_dtypes(include=['int64']).columns:
        if df[col].min() >= 0:
            if df[col].max() < 255:
                df[col] = df[col].astype('uint8')
            elif df[col].max() < 65535:
                df[col] = df[col].astype('uint16')
            else:
                df[col] = df[col].astype('uint32')
    
    for col in df.select_dtypes(include=['float64']).columns:
        df[col] = pd.to_numeric(df[col], downcast='float')
    
    return df
```

### Reproducibilidad y Debugging
```python
# ConfiguraciÃ³n de semillas para reproducibilidad
import random
import os

def set_random_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

# Logging detallado para debugging
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def log_data_info(df, name):
    logger.info(f"Dataset {name}: {df.shape[0]} filas, {df.shape[1]} columnas")
    logger.info(f"Memoria usada: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    logger.info(f"Valores nulos: {df.isnull().sum().sum()}")
```

## ðŸ“ž Contacto y ColaboraciÃ³n

Para consultas tÃ©cnicas, colaboraciones en proyectos de forecasting, o discusiones sobre aplicaciones de machine learning en retail y supply chain, no dudes en contactar.

## ðŸ“— Referencias y Recursos

- **CatBoost Documentation:** GuÃ­a oficial y best practices
- **Time Series Forecasting:** Literatura sobre predicciÃ³n en retail
- **Feature Engineering:** TÃ©cnicas avanzadas para series temporales
- **Kaggle Competitions:** AnÃ¡lisis de soluciones ganadoras en forecasting

---

*Este proyecto representa una aplicaciÃ³n integral de machine learning para forecasting en retail, combinando mÃºltiples fuentes de datos, ingenierÃ­a de caracterÃ­sticas avanzada y el poder de CatBoost para crear predicciones precisas de ventas que pueden impulsar decisiones estratÃ©gicas en el mundo real.*