# EEDI Mining Misconceptions in Mathematics - NLP Fine-Tuning Project

Este proyecto implementa una soluci√≥n completa para la competici√≥n de Kaggle "EEDI - Mining Misconceptions in Mathematics" utilizando t√©cnicas avanzadas de procesamiento de lenguaje natural (NLP) y fine-tuning de modelos transformer. El objetivo es identificar y mapear conceptos err√≥neos matem√°ticos en respuestas incorrectas de estudiantes mediante el an√°lisis de preguntas y opciones de respuesta.

## üß† Descripci√≥n del Proyecto

El proyecto utiliza el modelo **Flan-T5** pre-entrenado para realizar fine-tuning espec√≠fico en el dominio de educaci√≥n matem√°tica. A trav√©s de la generaci√≥n de prompts estructurados y el entrenamiento con datos etiquetados, se construye un sistema inteligente capaz de identificar autom√°ticamente los conceptos err√≥neos subyacentes en las respuestas incorrectas de estudiantes.

## üìä Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|-----------|------------|---------|-----------|
| **Lenguaje** | Python | 3.x | Lenguaje principal de desarrollo |
| **Deep Learning** | PyTorch | - | Framework de deep learning |
| **Transformers** | Hugging Face Transformers | - | Modelos de lenguaje pre-entrenados |
| **Modelo Base** | Flan-T5 Base | - | Modelo transformer para fine-tuning |
| **An√°lisis de Datos** | Pandas | - | Manipulaci√≥n de datasets educativos |
| **An√°lisis de Datos** | NumPy | - | Operaciones num√©ricas y vectoriales |
| **Machine Learning** | Scikit-learn | - | M√©tricas de evaluaci√≥n y preprocesamiento |
| **Datasets** | Hugging Face Datasets | - | Manejo eficiente de datos para training |
| **NLP Training** | Trainer API | - | Entrenamiento simplificado de modelos |
| **M√©tricas** | Cosine Similarity | - | C√°lculo de similitud sem√°ntica |
| **Utilidades** | Tabulate | - | Formateo de resultados |
| **Serializaci√≥n** | JSON | - | Almacenamiento de prompts estructurados |

## üîÑ Pipeline de Desarrollo

### 1. **Carga y Exploraci√≥n de Datos**
```python
# Carga de datasets desde Kaggle
test = pd.read_csv("/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv")
train = pd.read_csv("/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv")
misconceptions_mapping = pd.read_csv("/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv")
```

**Datasets principales:**
- **train.csv:** Preguntas matem√°ticas con conceptos err√≥neos etiquetados
- **test.csv:** Conjunto de evaluaci√≥n sin etiquetas
- **misconceptions_mapping.csv:** Mapeo de IDs a descripciones de conceptos err√≥neos
- **sample_submission.csv:** Formato de env√≠o requerido

### 2. **Preprocesamiento y Limpieza de Datos**

#### Conversi√≥n de Tipos de Datos
```python
def convert_to_int(column):
    return column.apply(lambda x: int(x) if pd.notna(x) else pd.NA)

# Conversi√≥n a Int64 para manejo correcto de valores nulos
for column in ['MisconceptionAId', 'MisconceptionBId', 'MisconceptionCId', 'MisconceptionDId']:
    train[column] = train[column].astype('Int64')
```

**Beneficios:**
- **Manejo robusto de NaN:** Preservaci√≥n de valores faltantes
- **Tipado consistente:** Evita errores en operaciones posteriores
- **Compatibilidad:** Preparaci√≥n para an√°lisis estad√≠stico

#### Filtrado y An√°lisis de Frecuencias
```python
# Filtrar filas con al menos un concepto err√≥neo
filtered_train = train[
    train['MisconceptionAId'].notna() |
    train['MisconceptionBId'].notna() |
    train['MisconceptionCId'].notna() |
    train['MisconceptionDId'].notna()
]
```

### 3. **Generaci√≥n de Prompts Estructurados**

#### Formato de Prompt Educativo
```python
prompt = (
    f"Question: {row['QuestionText']}\n"
    "Possible Answers:\n"
    f"A: {row['AnswerAText']}\n"
    f"B: {row['AnswerBText']}\n"
    f"C: {row['AnswerCText']}\n"
    f"D: {row['AnswerDText']}\n"
    f"Correct Answer: {row['CorrectAnswer']}\n"
)
```

**Caracter√≠sticas del dise√±o:**
- **Estructura clara:** Formato pregunta-opciones-respuesta correcta
- **Contexto educativo:** Adaptado para an√°lisis de conceptos err√≥neos
- **Consistencia:** Formato uniforme para todo el dataset

#### Construcci√≥n de Completions
```python
misconceptions = []
for option in ['A', 'B', 'C', 'D']:
    misconception_id = row[f'Misconception{option}Id']
    if pd.notna(misconception_id) and misconception_id in misconceptions_dict:
        misconceptions.append(f"- Option {option}: {{id={int(misconception_id)}}} {misconceptions_dict[misconception_id]}")

completion = "\n".join(misconceptions) if misconceptions else "No misconceptions available."
```

**Innovaci√≥n:**
- **Mapeo autom√°tico:** ID a descripci√≥n textual de conceptos err√≥neos
- **Estructura jer√°rquica:** Organizaci√≥n por opci√≥n de respuesta
- **Manejo de casos edge:** Gesti√≥n de misconceptions faltantes

### 4. **Fine-Tuning del Modelo Flan-T5**

#### Configuraci√≥n del Modelo Base
```python
model_path = "/kaggle/input/flan-t5-base-v4"
tokenizer = T5Tokenizer.from_pretrained(model_path, legacy=False)
model = T5ForConditionalGeneration.from_pretrained(model_path)
```

**Justificaci√≥n de Flan-T5:**
- **Instrucci√≥n-following:** Dise√±ado para seguir instrucciones complejas
- **Versatilidad:** Excelente para tareas de generaci√≥n condicionada
- **Tama√±o eficiente:** Balance entre capacidad y recursos computacionales
- **Fine-tuning friendly:** Arquitectura optimizada para adaptaci√≥n espec√≠fica

#### Preparaci√≥n de Datasets
```python
# Divisi√≥n estratificada para training/validation
train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)

# Conversi√≥n a formato Hugging Face
train_dataset = Dataset.from_pandas(train_df)
eval_dataset = Dataset.from_pandas(eval_df)
```

### 5. **Entrenamiento y Evaluaci√≥n**

#### Configuraci√≥n de Training
```python
training_args = TrainingArguments(
    output_dir='/kaggle/working/flan-t5-finetuned',
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    logging_steps=10,
    evaluation_strategy='epoch',
    save_strategy='epoch'
)
```

#### Generaci√≥n de Predicciones
```python
model.eval()
for item in selected_prompts:
    inputs = tokenizer(item["prompt"], return_tensors='pt', padding=True, truncation=True, max_length=256).to("cuda")
    
    with torch.no_grad():
        outputs = model.generate(**inputs)
        pred_string = tokenizer.batch_decode(outputs, skip_special_tokens=True)
```

### 6. **M√©trica de Evaluaci√≥n: mAP@25**

#### C√°lculo de Embeddings Sem√°nticos
```python
def get_embeddings(texts):
    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=256).to("cuda")
    with torch.no_grad():
        outputs = model.base_model.encoder(**inputs)
    return outputs.last_hidden_state.mean(dim=1)
```

#### Implementaci√≥n de mAP@25
```python
def compute_map_at_25(predictions, labels):
    pred_vectors = get_embeddings(predictions).cpu().numpy()
    label_vectors = get_embeddings(labels).cpu().numpy()
    
    cosine_similarities = cosine_similarity(pred_vectors, label_vectors)
    
    map_at_25 = 0
    for i, (pred, true) in enumerate(zip(predictions, labels)):
        top_25_preds = sorted(range(len(cosine_similarities[i])), 
                             key=lambda k: cosine_similarities[i][k], reverse=True)[:25]
        # C√°lculo de precisi√≥n promedio
        # ... [l√≥gica de relevancia y ranking]
```

**Caracter√≠sticas de la m√©trica:**
- **Ranking-based:** Eval√∫a la calidad del ordenamiento de predicciones
- **Top-K evaluation:** Foco en las 25 mejores predicciones
- **Similitud sem√°ntica:** Uso de cosine similarity para comparaci√≥n
- **Educaci√≥n-espec√≠fica:** Adaptada para conceptos err√≥neos matem√°ticos

## üìÅ Estructura del Proyecto (Kaggle Environment)

### Entorno de Kaggle - Archivos y Datasets Disponibles:

```
COMPETITIONS:
‚îî‚îÄ‚îÄ eedi-mining-misconceptions-in-mathematics/
    ‚îú‚îÄ‚îÄ train.csv                              # Dataset de entrenamiento
    ‚îú‚îÄ‚îÄ test.csv                              # Dataset de evaluaci√≥n  
    ‚îú‚îÄ‚îÄ sample_submission.csv                 # Formato de env√≠o
    ‚îî‚îÄ‚îÄ misconception_mapping.csv             # Mapeo ID-concepto err√≥neo

MODELS:
‚îî‚îÄ‚îÄ flan-t5-base-v4/
    ‚îú‚îÄ‚îÄ .gitattributes                        # Atributos de Git
    ‚îú‚îÄ‚îÄ README.md                             # Documentaci√≥n del modelo
    ‚îú‚îÄ‚îÄ config.json                           # Configuraci√≥n del modelo
    ‚îú‚îÄ‚îÄ flax_model.msgpack                    # Modelo en formato Flax
    ‚îú‚îÄ‚îÄ generation_config.json                # Configuraci√≥n de generaci√≥n
    ‚îú‚îÄ‚îÄ model.safetensors                     # Modelo principal
    ‚îú‚îÄ‚îÄ pytorch_model.bin                     # Modelo PyTorch
    ‚îú‚îÄ‚îÄ special_tokens_map.json               # Mapeo de tokens especiales
    ‚îú‚îÄ‚îÄ spiece.model                          # Modelo SentencePiece
    ‚îú‚îÄ‚îÄ tf_model.h5                          # Modelo TensorFlow
    ‚îú‚îÄ‚îÄ tokenizer.json                        # Tokenizador
    ‚îî‚îÄ‚îÄ tokenizer_config.json                 # Configuraci√≥n del tokenizador

NOTEBOOK:
‚îî‚îÄ‚îÄ misconception1_flan.ipynb                 # Notebook principal del proyecto

OUTPUT (/kaggle/working/):
‚îú‚îÄ‚îÄ fine_tuning_prompts.json                  # Prompts generados
‚îú‚îÄ‚îÄ flan-t5-finetuned/                       # Modelo fine-tuneado
‚îî‚îÄ‚îÄ submission.csv                            # Archivo de env√≠o
```

### Rutas de Acceso en C√≥digo:
```python
# Datos de entrada desde competitions
TRAIN_PATH = "/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv"
TEST_PATH = "/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv"
MISCONCEPTIONS_PATH = "/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv"
SAMPLE_SUBMISSION_PATH = "/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv"

# Modelo pre-entrenado desde models
MODEL_PATH = "/kaggle/input/flan-t5-base-v4"
TOKENIZER_PATH = "/kaggle/input/flan-t5-base-v4"

# Outputs en working directory
FINETUNED_MODEL_PATH = "/kaggle/working/flan-t5-finetuned"
PROMPTS_PATH = "/kaggle/working/fine_tuning_prompts.json"
SUBMISSION_PATH = "/kaggle/working/submission.csv"
```

## üöÄ C√≥mo Ejecutar el Proyecto en Kaggle

### Configuraci√≥n del Entorno Kaggle
```python
# Las librer√≠as principales ya est√°n disponibles en Kaggle
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments
from datasets import Dataset
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import json
```

### Verificaci√≥n de GPU y Datasets
```python
# Verificar disponibilidad de GPU
print("CUDA disponible:", torch.cuda.is_available())
print("GPU:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No disponible")

# Listar archivos disponibles en input
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
```

### Ejecuci√≥n Paso a Paso

#### Paso 1: Crear y ejecutar un nuevo notebook
1. **Fork del notebook** `misconception1_flan.ipynb`
2. **Configurar GPU**: Settings ‚Üí Accelerator ‚Üí GPU T4 x2
3. **Agregar datasets**:
   - **Competition Data**: EEDI - Mining Misconceptions in Mathematics
   - **Model**: flan-t5-base-v4 (incluye todos los archivos del modelo)

#### Paso 2: Verificar archivos disponibles
```python
# Verificar estructura de input
import os

print("=== COMPETITION DATA ===")
for file in os.listdir('/kaggle/input/eedi-mining-misconceptions-in-mathematics/'):
    print(f"üìÑ {file}")

print("\n=== MODEL FILES ===") 
for file in os.listdir('/kaggle/input/flan-t5-base-v4/'):
    print(f"ü§ñ {file}")
```

### Flujo de Ejecuci√≥n en Kaggle

#### 1. **Preparaci√≥n de Datos**
```python
# Cargar datasets desde input directory
train = pd.read_csv("/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv")
misconceptions_mapping = pd.read_csv("/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv")

# Convertir tipos y limpiar datos
for column in ['MisconceptionAId', 'MisconceptionBId', 'MisconceptionCId', 'MisconceptionDId']:
    train[column] = train[column].astype('Int64')
```

#### 2. **Generaci√≥n de Prompts**
```python
# Crear diccionario de mapeo
misconceptions_dict = {row['MisconceptionId']: row['MisconceptionName'] 
                      for index, row in misconceptions_mapping.iterrows()}

# Generar y guardar prompts en working directory
prompts = []
for index, row in train.iterrows():
    # ... [l√≥gica de generaci√≥n de prompts]

# Guardar en /kaggle/working/
with open('/kaggle/working/fine_tuning_prompts.json', 'w') as f:
    json.dump(prompts, f, indent=4)
```

#### 3. **Fine-Tuning del Modelo**
```python
# Cargar modelo base desde input/models
model_path = "/kaggle/input/flan-t5-base-v4"
tokenizer = T5Tokenizer.from_pretrained(model_path, legacy=False)
model = T5ForConditionalGeneration.from_pretrained(model_path)

# Preparar datasets
train_dataset = Dataset.from_pandas(train_df)
eval_dataset = Dataset.from_pandas(eval_df)

# Configurar training arguments para guardar en working
training_args = TrainingArguments(
    output_dir='/kaggle/working/flan-t5-finetuned',
    # ... otros par√°metros
)

# Entrenar modelo
trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset)
trainer.train()
```

#### 4. **Evaluaci√≥n y Predicci√≥n**
```python
# Cargar modelo fine-tuneado desde working directory
model = T5ForConditionalGeneration.from_pretrained("/kaggle/working/flan-t5-finetuned")
model.to("cuda")  # Usar GPU de Kaggle

# Generar predicciones
predictions = []
for prompt in test_prompts:
    inputs = tokenizer(prompt, return_tensors='pt').to("cuda")
    outputs = model.generate(**inputs)
    predictions.append(tokenizer.decode(outputs[0], skip_special_tokens=True))

# Guardar submission en working directory
submission.to_csv('/kaggle/working/submission.csv', index=False)
```

## üìà Resultados y M√©tricas

### Modelo Principal: Flan-T5 Fine-Tuned
**Configuraci√≥n optimizada:**
- **Arquitectura:** T5 (Text-to-Text Transfer Transformer)
- **Tama√±o:** Base (220M par√°metros)
- **Epochs:** 3 (balance entre overfitting y convergencia)
- **Batch Size:** 8 (optimizado para GPU disponible)
- **Learning Rate:** Adaptativo seg√∫n Trainer defaults

### M√©tricas de Evaluaci√≥n
- **M√©trica principal:** mAP@25 (Mean Average Precision at 25)
- **Similitud sem√°ntica:** Cosine similarity entre embeddings
- **Precisi√≥n:** Evaluaci√≥n en top-25 predicciones
- **An√°lisis cualitativo:** Revisi√≥n manual de conceptos err√≥neos identificados

### Insights Educativos
1. **Patrones de conceptos err√≥neos:** Identificaci√≥n de misconceptions comunes
2. **Distribuci√≥n por temas:** An√°lisis de √°reas matem√°ticas problem√°ticas
3. **Correlaciones:** Relaciones entre tipos de preguntas y errores espec√≠ficos
4. **Calidad de predicciones:** Evaluaci√≥n de coherencia sem√°ntica

## üî¨ Innovaciones T√©cnicas

### Fortalezas del Enfoque NLP
1. **Fine-tuning especializado:** Adaptaci√≥n espec√≠fica al dominio educativo
2. **Prompts estructurados:** Dise√±o optimizado para comprensi√≥n de contexto
3. **Embeddings sem√°nticos:** Representaci√≥n vectorial de conceptos err√≥neos
4. **Evaluaci√≥n ranking-based:** M√©trica adaptada al problema espec√≠fico

### Aspectos √önicos del Proyecto
- **Dominio educativo:** Aplicaci√≥n de NLP a educaci√≥n matem√°tica
- **Identificaci√≥n autom√°tica:** Detecci√≥n de misconceptions sin supervisi√≥n directa
- **Transferencia de conocimiento:** Leverage de Flan-T5 pre-entrenado
- **M√©trica especializada:** mAP@25 para evaluaci√≥n de relevancia

## üéØ Posibles Mejoras

### T√©cnicas Avanzadas de NLP
1. **Ensemble de modelos:** Combinaci√≥n con BERT, RoBERTa, o GPT-variants
2. **Prompt engineering:** Optimizaci√≥n sistem√°tica de formatos de prompt
3. **Data augmentation:** Generaci√≥n sint√©tica de ejemplos de entrenamiento
4. **Knowledge distillation:** Transferencia desde modelos m√°s grandes

### Ingenier√≠a de Caracter√≠sticas Educativas
1. **An√°lisis de dificultad:** Incorporaci√≥n de m√©tricas de complejidad de preguntas
2. **Taxonom√≠a de errores:** Clasificaci√≥n jer√°rquica de conceptos err√≥neos
3. **Patrones temporales:** An√°lisis de evoluci√≥n de misconceptions
4. **Contexto curricular:** Integraci√≥n de informaci√≥n de curr√≠culo matem√°tico

### Optimizaci√≥n de Modelo
1. **Hyperparameter tuning:** Grid search sistem√°tico
2. **Learning rate scheduling:** Estrategias de decaimiento adaptativo
3. **Regularization techniques:** Dropout, weight decay optimizados
4. **Multi-task learning:** Entrenamiento conjunto en tareas relacionadas

## üéì Aplicaciones Educativas

### Impacto en Educaci√≥n Matem√°tica
- **Diagn√≥stico autom√°tico:** Identificaci√≥n r√°pida de conceptos err√≥neos
- **Feedback personalizado:** Respuestas espec√≠ficas a errores comunes
- **An√°lisis curricular:** Detecci√≥n de √°reas problem√°ticas en programas
- **Formaci√≥n docente:** Herramienta para entender patrones de error estudiantil

### Escalabilidad y Transferencia
1. **Otras disciplinas:** Adaptaci√≥n a ciencias, f√≠sica, qu√≠mica
2. **Diferentes idiomas:** Extensi√≥n a entornos multiling√ºes
3. **Niveles educativos:** Aplicaci√≥n desde primaria hasta universitario
4. **Sistemas adaptativos:** Integraci√≥n en plataformas de aprendizaje personalizado

## üîß Consideraciones T√©cnicas

### Consideraciones Espec√≠ficas de Kaggle

#### Limitaciones del Entorno
- **Tiempo de ejecuci√≥n:** M√°ximo 12 horas por sesi√≥n
- **Espacio en /working:** 20GB disponibles
- **GPU:** T4 x2 disponible para training
- **Internet:** Deshabilitado durante competici√≥n
- **Modelos pre-cargados:** Usar datasets de input para modelos

#### Optimizaciones para Kaggle
```python
# Configuraci√≥n de memoria eficiente
torch.cuda.empty_cache()

# Batch size optimizado para T4
BATCH_SIZE = 8  # Ajustar seg√∫n memoria disponible

# Checkpointing frecuente
training_args = TrainingArguments(
    output_dir='/kaggle/working/checkpoints',
    save_steps=500,  # Guardar cada 500 pasos
    logging_steps=100,
    dataloader_num_workers=2  # Optimizado para Kaggle
)
```

#### Gesti√≥n de Archivos
```python
# Verificar espacio disponible
import shutil
total, used, free = shutil.disk_usage('/kaggle/working')
print(f"Espacio libre: {free // (2**30)} GB")

# Limpiar archivos innecesarios
import gc
gc.collect()
torch.cuda.empty_cache()
```

### Reproducibilidad
- **Random seeds:** Fijados para consistencia de resultados
- **Versiones de librer√≠as:** Especificadas para compatibilidad
- **Checkpoints:** Guardado regular durante entrenamiento
- **Logging:** Registro detallado de m√©tricas y par√°metros

## üìû Contacto y Colaboraci√≥n

Para consultas t√©cnicas, colaboraciones en proyectos educativos, o discusiones sobre aplicaciones de NLP en educaci√≥n matem√°tica, no dudes en contactar.

## üîó Referencias y Recursos

- **Flan-T5 Paper:** "Scaling Instruction-Finetuned Language Models"
- **T5 Architecture:** "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
- **Educational NLP:** Literatura sobre aplicaciones de IA en educaci√≥n
- **Misconceptions Research:** Investigaci√≥n en conceptos err√≥neos matem√°ticos

---

*Este proyecto representa una aplicaci√≥n innovadora de t√©cnicas de NLP modernas al campo de la educaci√≥n matem√°tica, combinando fine-tuning especializado con an√°lisis sem√°ntico para crear una herramienta poderosa de identificaci√≥n autom√°tica de conceptos err√≥neos estudiantiles.*